{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat-and-dog-breeds-parameters', 'xlearn', 'densenet121weights', 'fasttext-english-word-vectors-including-subwords', 'kerascatvsdog', 'petfinder-adoption-prediction']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "split_char = '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat-and-dog-breeds-parameters', 'xlearn', 'densenet121weights', 'fasttext-english-word-vectors-including-subwords', 'kerascatvsdog', 'petfinder-adoption-prediction']\n",
      "['train', 'test', 'breed_labels.csv', 'train_sentiment', 'test_sentiment', 'test_metadata', 'train_images', 'train_metadata', 'state_labels.csv', 'color_labels.csv', 'test_images']\n",
      "['train.csv']\n",
      "['sample_submission.csv', 'test.csv']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from functools import partial\n",
    "from math import sqrt\n",
    "from sklearn.metrics import cohen_kappa_score as kappa_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix as sk_cmatrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import scipy as sp\n",
    "from skimage import feature\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import operator\n",
    "import cv2\n",
    "from scipy.stats import itemfreq\n",
    "from joblib import Parallel, delayed\n",
    "import json\n",
    "import string\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold\n",
    "from PIL import Image as IMG\n",
    "from PIL import Image\n",
    "import glob\n",
    "kappa_scorer = None\n",
    "\n",
    "import os\n",
    "os.environ['USER'] = 'root'\n",
    "os.system('pip install ../input/xlearn/xlearn/xlearn-0.40a1/')\n",
    "\n",
    "print(os.listdir(\"../input\"))\n",
    "print(os.listdir(\"../input/petfinder-adoption-prediction/\"))\n",
    "print(os.listdir(\"../input/petfinder-adoption-prediction/train\"))\n",
    "print(os.listdir(\"../input/petfinder-adoption-prediction/test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../input/petfinder-adoption-prediction/train/train.csv\")\n",
    "test_df = pd.read_csv(\"../input/petfinder-adoption-prediction/test/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df[\"AdoptionSpeed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_breed = pd.read_csv('../input/petfinder-adoption-prediction/breed_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../input/cat-and-dog-breeds-parameters/rating.json', 'r') as f:\n",
    "    ratings = json.load(f)\n",
    "cat_ratings = ratings['cat_breeds']\n",
    "dog_ratings = ratings['dog_breeds']\n",
    "breed_id = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_attributes = set(list(cat_ratings[\"Abyssinian\"].keys()) + list(dog_ratings[\"German Shepherd Dog\"].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pet_attributes:\n",
    "    train_df[i] = 0\n",
    "    test_df[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_ratings = {k.lower(): v for k, v in cat_ratings.items()}\n",
    "dog_ratings = {k.lower(): v for k, v in dog_ratings.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id,name in zip(labels_breed.BreedID,labels_breed.BreedName):\n",
    "    breed_id[id] = str(name).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id,name in zip(labels_breed.BreedID,labels_breed.BreedName):\n",
    "    breed_id[id] = str(name).lower()\n",
    "breed_names_1 = [i for i in cat_ratings.keys()]\n",
    "breed_names_2 = [i for i in dog_ratings.keys()]\n",
    "def breed_name(df):\n",
    "    for i, id in enumerate(df['Breed1']):\n",
    "        if id in breed_id.keys(): \n",
    "            name = str(breed_id[id]).lower() \n",
    "            if name in breed_names_1:\n",
    "                #print(cat_ratings[name])\n",
    "                for key in cat_ratings[name].keys():\n",
    "                    #print(key)\n",
    "                    df.loc[i, key] = cat_ratings[name][key]\n",
    "            if name in breed_names_2:\n",
    "                #print(dog_ratings[name])\n",
    "                for key in dog_ratings[name].keys():\n",
    "\n",
    "                    df.loc[i, key] = dog_ratings[name][key]\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of train images files: 58311\n",
      "num of train metadata files: 58311\n",
      "num of train sentiment files: 14442\n",
      "num of test images files: 14465\n",
      "num of test metadata files: 14465\n",
      "num of test sentiment files: 3865\n"
     ]
    }
   ],
   "source": [
    "train_image_files = sorted(glob.glob('../input/petfinder-adoption-prediction/train_images/*.jpg'))\n",
    "train_metadata_files = sorted(glob.glob('../input/petfinder-adoption-prediction/train_metadata/*.json'))\n",
    "train_sentiment_files = sorted(glob.glob('../input/petfinder-adoption-prediction/train_sentiment/*.json'))\n",
    "\n",
    "print('num of train images files: {}'.format(len(train_image_files)))\n",
    "print('num of train metadata files: {}'.format(len(train_metadata_files)))\n",
    "print('num of train sentiment files: {}'.format(len(train_sentiment_files)))\n",
    "\n",
    "\n",
    "test_image_files = sorted(glob.glob('../input/petfinder-adoption-prediction/test_images/*.jpg'))\n",
    "test_metadata_files = sorted(glob.glob('../input/petfinder-adoption-prediction/test_metadata/*.json'))\n",
    "test_sentiment_files = sorted(glob.glob('../input/petfinder-adoption-prediction/test_sentiment/*.json'))\n",
    "\n",
    "print('num of test images files: {}'.format(len(test_image_files)))\n",
    "print('num of test metadata files: {}'.format(len(test_metadata_files)))\n",
    "print('num of test sentiment files: {}'.format(len(test_sentiment_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14993, 1)\n",
      "14652\n",
      "fraction of pets with images: 0.977\n",
      "14652\n",
      "fraction of pets with metadata: 0.977\n",
      "14442\n",
      "fraction of pets with sentiment: 0.963\n"
     ]
    }
   ],
   "source": [
    "# Images:\n",
    "train_df_ids = train_df[['PetID']]\n",
    "print(train_df_ids.shape)\n",
    "\n",
    "train_df_imgs = pd.DataFrame(train_image_files)\n",
    "train_df_imgs.columns = ['image_filename']\n",
    "train_imgs_pets = train_df_imgs['image_filename'].apply(lambda x: x.split('/')[-1].split('-')[0])\n",
    "train_df_imgs = train_df_imgs.assign(PetID=train_imgs_pets)\n",
    "print(len(train_imgs_pets.unique()))\n",
    "\n",
    "pets_with_images = len(np.intersect1d(train_imgs_pets.unique(), train_df_ids['PetID'].unique()))\n",
    "print('fraction of pets with images: {:.3f}'.format(pets_with_images / train_df_ids.shape[0]))\n",
    "\n",
    "# Metadata:\n",
    "train_df_ids = train_df[['PetID']]\n",
    "train_df_metadata = pd.DataFrame(train_metadata_files)\n",
    "train_df_metadata.columns = ['metadata_filename']\n",
    "train_metadata_pets = train_df_metadata['metadata_filename'].apply(lambda x: x.split('/')[-1].split('-')[0])\n",
    "train_df_metadata = train_df_metadata.assign(PetID=train_metadata_pets)\n",
    "print(len(train_metadata_pets.unique()))\n",
    "\n",
    "pets_with_metadatas = len(np.intersect1d(train_metadata_pets.unique(), train_df_ids['PetID'].unique()))\n",
    "print('fraction of pets with metadata: {:.3f}'.format(pets_with_metadatas / train_df_ids.shape[0]))\n",
    "\n",
    "# Sentiment:\n",
    "train_df_ids = train_df[['PetID']]\n",
    "train_df_sentiment = pd.DataFrame(train_sentiment_files)\n",
    "train_df_sentiment.columns = ['sentiment_filename']\n",
    "train_sentiment_pets = train_df_sentiment['sentiment_filename'].apply(lambda x: x.split('/')[-1].split('.')[0])\n",
    "train_df_sentiment = train_df_sentiment.assign(PetID=train_sentiment_pets)\n",
    "print(len(train_sentiment_pets.unique()))\n",
    "\n",
    "pets_with_sentiments = len(np.intersect1d(train_sentiment_pets.unique(), train_df_ids['PetID'].unique()))\n",
    "print('fraction of pets with sentiment: {:.3f}'.format(pets_with_sentiments / train_df_ids.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3972, 1)\n",
      "3858\n",
      "fraction of pets with images: 0.971\n",
      "3858\n",
      "fraction of pets with metadata: 0.971\n",
      "3865\n",
      "fraction of pets with sentiment: 0.973\n",
      "images and metadata distributions the same? True\n"
     ]
    }
   ],
   "source": [
    "# Images:\n",
    "test_df_ids = test_df[['PetID']]\n",
    "print(test_df_ids.shape)\n",
    "\n",
    "test_df_imgs = pd.DataFrame(test_image_files)\n",
    "test_df_imgs.columns = ['image_filename']\n",
    "test_imgs_pets = test_df_imgs['image_filename'].apply(lambda x: x.split('/')[-1].split('-')[0])\n",
    "test_df_imgs = test_df_imgs.assign(PetID=test_imgs_pets)\n",
    "print(len(test_imgs_pets.unique()))\n",
    "\n",
    "pets_with_images = len(np.intersect1d(test_imgs_pets.unique(), test_df_ids['PetID'].unique()))\n",
    "print('fraction of pets with images: {:.3f}'.format(pets_with_images / test_df_ids.shape[0]))\n",
    "\n",
    "\n",
    "# Metadata:\n",
    "test_df_ids = test_df[['PetID']]\n",
    "test_df_metadata = pd.DataFrame(test_metadata_files)\n",
    "test_df_metadata.columns = ['metadata_filename']\n",
    "test_metadata_pets = test_df_metadata['metadata_filename'].apply(lambda x: x.split('/')[-1].split('-')[0])\n",
    "test_df_metadata = test_df_metadata.assign(PetID=test_metadata_pets)\n",
    "print(len(test_metadata_pets.unique()))\n",
    "\n",
    "pets_with_metadatas = len(np.intersect1d(test_metadata_pets.unique(), test_df_ids['PetID'].unique()))\n",
    "print('fraction of pets with metadata: {:.3f}'.format(pets_with_metadatas / test_df_ids.shape[0]))\n",
    "\n",
    "\n",
    "\n",
    "# Sentiment:\n",
    "test_df_ids = test_df[['PetID']]\n",
    "test_df_sentiment = pd.DataFrame(test_sentiment_files)\n",
    "test_df_sentiment.columns = ['sentiment_filename']\n",
    "test_sentiment_pets = test_df_sentiment['sentiment_filename'].apply(lambda x: x.split('/')[-1].split('.')[0])\n",
    "test_df_sentiment = test_df_sentiment.assign(PetID=test_sentiment_pets)\n",
    "print(len(test_sentiment_pets.unique()))\n",
    "\n",
    "pets_with_sentiments = len(np.intersect1d(test_sentiment_pets.unique(), test_df_ids['PetID'].unique()))\n",
    "print('fraction of pets with sentiment: {:.3f}'.format(pets_with_sentiments / test_df_ids.shape[0]))\n",
    "\n",
    "\n",
    "# are distributions the same?\n",
    "print('images and metadata distributions the same? {}'.format(\n",
    "    np.all(test_metadata_pets == test_imgs_pets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PetFinderParser(object):\n",
    "    \n",
    "    def __init__(self, debug=False):\n",
    "        \n",
    "        self.debug = debug\n",
    "        self.sentence_sep = ' '\n",
    "        \n",
    "        # Does not have to be extracted because main DF already contains description\n",
    "        self.extract_sentiment_text = False\n",
    "        \n",
    "        \n",
    "    def open_metadata_file(self, filename):\n",
    "        \"\"\"\n",
    "        Load metadata file.\n",
    "        \"\"\"\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            metadata_file = json.load(f)\n",
    "        return metadata_file\n",
    "            \n",
    "    def open_sentiment_file(self, filename):\n",
    "        \"\"\"\n",
    "        Load sentiment file.\n",
    "        \"\"\"\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            sentiment_file = json.load(f)\n",
    "        return sentiment_file\n",
    "            \n",
    "    def open_image_file(self, filename):\n",
    "        \"\"\"\n",
    "        Load image file.\n",
    "        \"\"\"\n",
    "        image = np.asarray(Image.open(filename))\n",
    "        return image\n",
    "        \n",
    "    def parse_sentiment_file(self, file):\n",
    "        \"\"\"\n",
    "        Parse sentiment file. Output DF with sentiment features.\n",
    "        \"\"\"\n",
    "        \n",
    "        file_sentiment = file['documentSentiment']\n",
    "        file_entities = [x['name'] for x in file['entities']]\n",
    "        file_entities = self.sentence_sep.join(file_entities)\n",
    "\n",
    "        if self.extract_sentiment_text:\n",
    "            file_sentences_text = [x['text']['content'] for x in file['sentences']]\n",
    "            file_sentences_text = self.sentence_sep.join(file_sentences_text)\n",
    "        file_sentences_sentiment = [x['sentiment'] for x in file['sentences']]\n",
    "        \n",
    "        file_sentences_sentiment = pd.DataFrame.from_dict(\n",
    "            file_sentences_sentiment, orient='columns').sum()\n",
    "        file_sentences_sentiment = file_sentences_sentiment.add_prefix('document_').to_dict()\n",
    "        \n",
    "        file_sentiment.update(file_sentences_sentiment)\n",
    "        \n",
    "        df_sentiment = pd.DataFrame.from_dict(file_sentiment, orient='index').T\n",
    "        if self.extract_sentiment_text:\n",
    "            df_sentiment['text'] = file_sentences_text\n",
    "            \n",
    "        df_sentiment['entities'] = file_entities\n",
    "        df_sentiment = df_sentiment.add_prefix('sentiment_')\n",
    "        \n",
    "        return df_sentiment\n",
    "    \n",
    "    def parse_metadata_file(self, file):\n",
    "        \"\"\"\n",
    "        Parse metadata file. Output DF with metadata features.\n",
    "        \"\"\"\n",
    "        \n",
    "        file_keys = list(file.keys())\n",
    "        \n",
    "        if 'labelAnnotations' in file_keys:\n",
    "            file_annots = file['labelAnnotations'][:int(len(file['labelAnnotations']) * 0.3)]\n",
    "            file_top_score = np.asarray([x['score'] for x in file_annots]).mean()\n",
    "            file_top_desc = [x['description'] for x in file_annots]\n",
    "        else:\n",
    "            file_top_score = np.nan\n",
    "            file_top_desc = ['']\n",
    "        \n",
    "        file_colors = file['imagePropertiesAnnotation']['dominantColors']['colors']\n",
    "        file_crops = file['cropHintsAnnotation']['cropHints']\n",
    "\n",
    "        file_color_score = np.asarray([x['score'] for x in file_colors]).mean()\n",
    "        file_color_pixelfrac = np.asarray([x['pixelFraction'] for x in file_colors]).mean()\n",
    "\n",
    "        file_crop_conf = np.asarray([x['confidence'] for x in file_crops]).mean()\n",
    "        \n",
    "        if 'importanceFraction' in file_crops[0].keys():\n",
    "            file_crop_importance = np.asarray([x['importanceFraction'] for x in file_crops]).mean()\n",
    "        else:\n",
    "            file_crop_importance = np.nan\n",
    "\n",
    "        df_metadata = {\n",
    "            'annots_score': file_top_score,\n",
    "            'color_score': file_color_score,\n",
    "            'color_pixelfrac': file_color_pixelfrac,\n",
    "            'crop_conf': file_crop_conf,\n",
    "            'crop_importance': file_crop_importance,\n",
    "            'annots_top_desc': self.sentence_sep.join(file_top_desc)\n",
    "        }\n",
    "        \n",
    "        df_metadata = pd.DataFrame.from_dict(df_metadata, orient='index').T\n",
    "        df_metadata = df_metadata.add_prefix('metadata_')\n",
    "        \n",
    "        return df_metadata\n",
    "    \n",
    "\n",
    "# Helper function for parallel data processing:\n",
    "def extract_additional_features(pet_id, mode='train'):\n",
    "    \n",
    "    sentiment_filename = '../input/petfinder-adoption-prediction/{}_sentiment/{}.json'.format(mode, pet_id)\n",
    "    try:\n",
    "        sentiment_file = pet_parser.open_sentiment_file(sentiment_filename)\n",
    "        df_sentiment = pet_parser.parse_sentiment_file(sentiment_file)\n",
    "        df_sentiment['PetID'] = pet_id\n",
    "    except:\n",
    "        df_sentiment = []\n",
    "\n",
    "    dfs_metadata = []\n",
    "    metadata_filenames = sorted(glob.glob('../input/petfinder-adoption-prediction/{}_metadata/{}*.json'.format(mode, pet_id)))\n",
    "    if len(metadata_filenames) > 0:\n",
    "        for f in metadata_filenames:\n",
    "            metadata_file = pet_parser.open_metadata_file(f)\n",
    "            df_metadata = pet_parser.parse_metadata_file(metadata_file)\n",
    "            df_metadata['PetID'] = pet_id\n",
    "            dfs_metadata.append(df_metadata)\n",
    "        dfs_metadata = pd.concat(dfs_metadata, ignore_index=True, sort=False)\n",
    "    dfs = [df_sentiment, dfs_metadata]\n",
    "    \n",
    "    return dfs\n",
    "\n",
    "\n",
    "pet_parser = PetFinderParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:   26.1s\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed:   45.5s\n",
      "[Parallel(n_jobs=6)]: Done 788 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=6)]: Done 1238 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=6)]: Done 1788 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=6)]: Done 2438 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=6)]: Done 3188 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=6)]: Done 4038 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=6)]: Done 4988 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=6)]: Done 6038 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=6)]: Done 7188 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=6)]: Done 8438 tasks      | elapsed: 10.5min\n",
      "[Parallel(n_jobs=6)]: Done 9788 tasks      | elapsed: 12.0min\n",
      "[Parallel(n_jobs=6)]: Done 11238 tasks      | elapsed: 13.7min\n",
      "[Parallel(n_jobs=6)]: Done 12788 tasks      | elapsed: 15.5min\n",
      "[Parallel(n_jobs=6)]: Done 14438 tasks      | elapsed: 17.5min\n",
      "[Parallel(n_jobs=6)]: Done 14993 out of 14993 | elapsed: 18.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14442, 6) (58311, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  64 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=6)]: Done 364 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=6)]: Done 864 tasks      | elapsed:   25.8s\n",
      "[Parallel(n_jobs=6)]: Done 1564 tasks      | elapsed:   46.6s\n",
      "[Parallel(n_jobs=6)]: Done 2464 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=6)]: Done 3564 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=6)]: Done 3972 out of 3972 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3865, 6) (14465, 7)\n"
     ]
    }
   ],
   "source": [
    "# Unique IDs from train and test:\n",
    "debug = False\n",
    "train_pet_ids = train_df.PetID.unique()\n",
    "test_pet_ids = test_df.PetID.unique()\n",
    "\n",
    "if debug:\n",
    "    train_pet_ids = train_pet_ids[:1000]\n",
    "    test_pet_ids = test_pet_ids[:500]\n",
    "\n",
    "\n",
    "# Train set:\n",
    "# Parallel processing of data:\n",
    "dfs_train = Parallel(n_jobs=6, verbose=1)(\n",
    "    delayed(extract_additional_features)(i, mode='train') for i in train_pet_ids)\n",
    "\n",
    "# Extract processed data and format them as DFs:\n",
    "train_dfs_sentiment = [x[0] for x in dfs_train if isinstance(x[0], pd.DataFrame)]\n",
    "train_dfs_metadata = [x[1] for x in dfs_train if isinstance(x[1], pd.DataFrame)]\n",
    "\n",
    "train_dfs_sentiment = pd.concat(train_dfs_sentiment, ignore_index=True, sort=False)\n",
    "train_dfs_metadata = pd.concat(train_dfs_metadata, ignore_index=True, sort=False)\n",
    "\n",
    "print(train_dfs_sentiment.shape, train_dfs_metadata.shape)\n",
    "\n",
    "\n",
    "# Test set:\n",
    "# Parallel processing of data:\n",
    "dfs_test = Parallel(n_jobs=6, verbose=1)(\n",
    "    delayed(extract_additional_features)(i, mode='test') for i in test_pet_ids)\n",
    "\n",
    "# Extract processed data and format them as DFs:\n",
    "test_dfs_sentiment = [x[0] for x in dfs_test if isinstance(x[0], pd.DataFrame)]\n",
    "test_dfs_metadata = [x[1] for x in dfs_test if isinstance(x[1], pd.DataFrame)]\n",
    "\n",
    "test_dfs_sentiment = pd.concat(test_dfs_sentiment, ignore_index=True, sort=False)\n",
    "test_dfs_metadata = pd.concat(test_dfs_metadata, ignore_index=True, sort=False)\n",
    "\n",
    "print(test_dfs_sentiment.shape, test_dfs_metadata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend aggregates and improve column naming\n",
    "aggregates = ['mean', 'sum', 'var', 'max', 'min']\n",
    "\n",
    "# Train\n",
    "train_metadata_desc = train_dfs_metadata.groupby(['PetID'])['metadata_annots_top_desc'].unique()\n",
    "train_metadata_desc = train_metadata_desc.reset_index()\n",
    "train_metadata_desc[\n",
    "    'metadata_annots_top_desc'] = train_metadata_desc[\n",
    "    'metadata_annots_top_desc'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "prefix = 'metadata'\n",
    "train_metadata_gr = train_dfs_metadata.drop(['metadata_annots_top_desc'], axis=1)\n",
    "for i in train_metadata_gr.columns:\n",
    "    if 'PetID' not in i:\n",
    "        train_metadata_gr[i] = train_metadata_gr[i].astype(float)\n",
    "train_metadata_gr = train_metadata_gr.groupby(['PetID']).agg(aggregates)\n",
    "train_metadata_gr.columns = pd.Index(['{}_{}_{}'.format(\n",
    "            prefix, c[0], c[1].upper()) for c in train_metadata_gr.columns.tolist()])\n",
    "train_metadata_gr = train_metadata_gr.reset_index()\n",
    "\n",
    "\n",
    "train_sentiment_desc = train_dfs_sentiment.groupby(['PetID'])['sentiment_entities'].unique()\n",
    "train_sentiment_desc = train_sentiment_desc.reset_index()\n",
    "train_sentiment_desc[\n",
    "    'sentiment_entities'] = train_sentiment_desc[\n",
    "    'sentiment_entities'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "prefix = 'sentiment'\n",
    "train_sentiment_gr = train_dfs_sentiment.drop(['sentiment_entities'], axis=1)\n",
    "for i in train_sentiment_gr.columns:\n",
    "    if 'PetID' not in i:\n",
    "        train_sentiment_gr[i] = train_sentiment_gr[i].astype(float)\n",
    "train_sentiment_gr = train_sentiment_gr.groupby(['PetID']).agg(aggregates)\n",
    "train_sentiment_gr.columns = pd.Index(['{}_{}_{}'.format(\n",
    "            prefix, c[0], c[1].upper()) for c in train_sentiment_gr.columns.tolist()])\n",
    "train_sentiment_gr = train_sentiment_gr.reset_index()\n",
    "\n",
    "\n",
    "# Test\n",
    "test_metadata_desc = test_dfs_metadata.groupby(['PetID'])['metadata_annots_top_desc'].unique()\n",
    "test_metadata_desc = test_metadata_desc.reset_index()\n",
    "test_metadata_desc[\n",
    "    'metadata_annots_top_desc'] = test_metadata_desc[\n",
    "    'metadata_annots_top_desc'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "prefix = 'metadata'\n",
    "test_metadata_gr = test_dfs_metadata.drop(['metadata_annots_top_desc'], axis=1)\n",
    "for i in test_metadata_gr.columns:\n",
    "    if 'PetID' not in i:\n",
    "        test_metadata_gr[i] = test_metadata_gr[i].astype(float)\n",
    "test_metadata_gr = test_metadata_gr.groupby(['PetID']).agg(aggregates)\n",
    "test_metadata_gr.columns = pd.Index(['{}_{}_{}'.format(\n",
    "            prefix, c[0], c[1].upper()) for c in test_metadata_gr.columns.tolist()])\n",
    "test_metadata_gr = test_metadata_gr.reset_index()\n",
    "\n",
    "\n",
    "test_sentiment_desc = test_dfs_sentiment.groupby(['PetID'])['sentiment_entities'].unique()\n",
    "test_sentiment_desc = test_sentiment_desc.reset_index()\n",
    "test_sentiment_desc[\n",
    "    'sentiment_entities'] = test_sentiment_desc[\n",
    "    'sentiment_entities'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "prefix = 'sentiment'\n",
    "test_sentiment_gr = test_dfs_sentiment.drop(['sentiment_entities'], axis=1)\n",
    "for i in test_sentiment_gr.columns:\n",
    "    if 'PetID' not in i:\n",
    "        test_sentiment_gr[i] = test_sentiment_gr[i].astype(float)\n",
    "test_sentiment_gr = test_sentiment_gr.groupby(['PetID']).agg(aggregates)\n",
    "test_sentiment_gr.columns = pd.Index(['{}_{}_{}'.format(\n",
    "            prefix, c[0], c[1].upper()) for c in test_sentiment_gr.columns.tolist()])\n",
    "test_sentiment_gr = test_sentiment_gr.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14993, 107) (3972, 106)\n"
     ]
    }
   ],
   "source": [
    "# Train merges:\n",
    "train_proc = train_df.copy()\n",
    "train_proc = train_proc.merge(\n",
    "    train_sentiment_gr, how='left', on='PetID')\n",
    "train_proc = train_proc.merge(\n",
    "    train_metadata_gr, how='left', on='PetID')\n",
    "train_proc = train_proc.merge(\n",
    "    train_metadata_desc, how='left', on='PetID')\n",
    "train_proc = train_proc.merge(\n",
    "    train_sentiment_desc, how='left', on='PetID')\n",
    "\n",
    "# Test merges:\n",
    "test_proc = test_df.copy()\n",
    "test_proc = test_proc.merge(\n",
    "    test_sentiment_gr, how='left', on='PetID')\n",
    "test_proc = test_proc.merge(\n",
    "    test_metadata_gr, how='left', on='PetID')\n",
    "test_proc = test_proc.merge(\n",
    "    test_metadata_desc, how='left', on='PetID')\n",
    "test_proc = test_proc.merge(\n",
    "    test_sentiment_desc, how='left', on='PetID')\n",
    "\n",
    "\n",
    "print(train_proc.shape, test_proc.shape)\n",
    "# assert train_proc.shape[0] == train_df.shape[0]\n",
    "# assert test_proc.shape[0] == test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN structure:\n",
      "Type                                          0\n",
      "Name                                       1668\n",
      "Age                                           0\n",
      "Breed1                                        0\n",
      "Breed2                                        0\n",
      "Gender                                        0\n",
      "Color1                                        0\n",
      "Color2                                        0\n",
      "Color3                                        0\n",
      "MaturitySize                                  0\n",
      "FurLength                                     0\n",
      "Vaccinated                                    0\n",
      "Dewormed                                      0\n",
      "Sterilized                                    0\n",
      "Health                                        0\n",
      "Quantity                                      0\n",
      "Fee                                           0\n",
      "State                                         0\n",
      "RescuerID                                     0\n",
      "VideoAmt                                      0\n",
      "Description                                  13\n",
      "PetID                                         0\n",
      "PhotoAmt                                      0\n",
      "AdoptionSpeed                              3972\n",
      "Easy To Train                                 0\n",
      "Amount Of Shedding                            0\n",
      "Intensity                                     0\n",
      " Exercise Needs                               0\n",
      "Tolerates Being Alone                         0\n",
      "Potential For Weight Gain                     0\n",
      "                                          ...  \n",
      "sentiment_sentiment_document_score_VAR    18965\n",
      "sentiment_sentiment_document_score_MAX      658\n",
      "sentiment_sentiment_document_score_MIN      658\n",
      "metadata_metadata_annots_score_MEAN         473\n",
      "metadata_metadata_annots_score_SUM          455\n",
      "metadata_metadata_annots_score_VAR         4505\n",
      "metadata_metadata_annots_score_MAX          473\n",
      "metadata_metadata_annots_score_MIN          473\n",
      "metadata_metadata_color_score_MEAN          455\n",
      "metadata_metadata_color_score_SUM           455\n",
      "metadata_metadata_color_score_VAR          4470\n",
      "metadata_metadata_color_score_MAX           455\n",
      "metadata_metadata_color_score_MIN           455\n",
      "metadata_metadata_color_pixelfrac_MEAN      455\n",
      "metadata_metadata_color_pixelfrac_SUM       455\n",
      "metadata_metadata_color_pixelfrac_VAR      4470\n",
      "metadata_metadata_color_pixelfrac_MAX       455\n",
      "metadata_metadata_color_pixelfrac_MIN       455\n",
      "metadata_metadata_crop_conf_MEAN            455\n",
      "metadata_metadata_crop_conf_SUM             455\n",
      "metadata_metadata_crop_conf_VAR            4470\n",
      "metadata_metadata_crop_conf_MAX             455\n",
      "metadata_metadata_crop_conf_MIN             455\n",
      "metadata_metadata_crop_importance_MEAN      456\n",
      "metadata_metadata_crop_importance_SUM       455\n",
      "metadata_metadata_crop_importance_VAR      4472\n",
      "metadata_metadata_crop_importance_MAX       456\n",
      "metadata_metadata_crop_importance_MIN       456\n",
      "metadata_annots_top_desc                    455\n",
      "sentiment_entities                          658\n",
      "Length: 107, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = pd.concat([train_proc, test_proc], ignore_index=True, sort=False, axis = 0)\n",
    "print('NaN structure:\\n{}'.format(np.sum(pd.isnull(X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp = X.copy()\n",
    "text_columns = ['Description', 'metadata_annots_top_desc', 'sentiment_entities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py:630: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n"
     ]
    }
   ],
   "source": [
    "# Count RescuerID occurrences:\n",
    "rescuer_count = X.groupby(['RescuerID'])['PetID'].count().reset_index()\n",
    "rescuer_count.columns = ['RescuerID', 'RescuerID_COUNT']\n",
    "\n",
    "# Merge as another feature onto main DF:\n",
    "X_temp = X_temp.merge(rescuer_count, how='left', on='RescuerID')\n",
    "\n",
    "# Count Unique breed occurrences:\n",
    "unique_count = X.groupby(['RescuerID'])['Breed1'].nunique().reset_index()\n",
    "unique_count.columns = ['RescuerID', 'RescuerID_UNIQUE']\n",
    "\n",
    "# Merge as another feature onto main DF:\n",
    "X_temp = X_temp.merge(unique_count, how='left', on='RescuerID')\n",
    "\n",
    "\n",
    "# Subset text features:\n",
    "X_text = X_temp[text_columns]\n",
    "\n",
    "for i in X_text.columns:\n",
    "    X_text.loc[:, i] = X_text.loc[:, i].fillna('<MISSING>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating features from: Description\n",
      "generating features from: metadata_annots_top_desc\n",
      "generating features from: sentiment_entities\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import SparsePCA, TruncatedSVD, LatentDirichletAllocation, NMF\n",
    "\n",
    "n_components = 16\n",
    "text_features = []\n",
    "\n",
    "\n",
    "# Generate text features:\n",
    "for i in X_text.columns:\n",
    "    \n",
    "    # Initialize decomposition methods:\n",
    "    print('generating features from: {}'.format(i))\n",
    "    svd_ = TruncatedSVD(\n",
    "        n_components=n_components, random_state=1337)\n",
    "    \n",
    "    tfidf_col = TfidfVectorizer().fit_transform(X_text.loc[:, i].values)\n",
    "    svd_col = svd_.fit_transform(tfidf_col)\n",
    "    svd_col = pd.DataFrame(svd_col)\n",
    "    svd_col = svd_col.add_prefix('SVD_{}_'.format(i))\n",
    "    text_features.append(svd_col)\n",
    "\n",
    "    \n",
    "# Combine all extracted features:\n",
    "text_features = pd.concat(text_features, axis=1)\n",
    "\n",
    "# Concatenate with main DF:\n",
    "X_temp = pd.concat([X_temp.reset_index(drop = True), text_features], axis=1)\n",
    "text_columns = ['metadata_annots_top_desc', 'sentiment_entities']\n",
    "# Remove raw text columns:\n",
    "for i in text_columns:\n",
    "    X_temp = X_temp.drop(i, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = X_temp.loc[np.isfinite(X_temp.AdoptionSpeed), :]\n",
    "test_df = X_temp.loc[~np.isfinite(X_temp.AdoptionSpeed), :]\n",
    "\n",
    "# Remove missing target column from test:\n",
    "test_df = test_df.drop(['AdoptionSpeed'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['Breed1','Breed2', 'Gender', 'Color1', 'Color2', 'Color3', 'State']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['Fee', 'Age', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n",
    " 'Sterilized', 'Health', 'Quantity', 'VideoAmt', 'PhotoAmt',\n",
    " 'Type','sentiment_sentiment_magnitude_MEAN', 'sentiment_sentiment_magnitude_SUM',\n",
    " 'sentiment_sentiment_score_MEAN', 'sentiment_sentiment_score_SUM', \n",
    " 'sentiment_sentiment_document_magnitude_MEAN', 'sentiment_sentiment_document_magnitude_SUM',\n",
    " 'sentiment_sentiment_document_score_MEAN', 'sentiment_sentiment_document_score_SUM',\n",
    " 'metadata_metadata_annots_score_MEAN', 'metadata_metadata_annots_score_SUM', 'metadata_metadata_color_score_MEAN',\n",
    " 'metadata_metadata_color_score_SUM', 'metadata_metadata_color_pixelfrac_MEAN', 'metadata_metadata_color_pixelfrac_SUM',\n",
    " 'metadata_metadata_crop_conf_MEAN', 'metadata_metadata_crop_conf_SUM', 'metadata_metadata_crop_importance_MEAN',\n",
    " 'metadata_metadata_crop_importance_SUM', 'RescuerID_COUNT', \n",
    " 'agg_mean_Age', 'agg_mean_Gender', 'agg_mean_Color1',\n",
    " 'agg_mean_Color2', 'agg_mean_Color3', 'agg_mean_FurLength', 'agg_mean_Vaccinated', 'agg_mean_Dewormed',\n",
    " 'agg_mean_Sterilized', 'agg_mean_Health', 'agg_mean_Quantity', 'agg_mean_Fee', 'agg_mean_PhotoAmt',\n",
    " 'agg_mean_VideoAmt', 'agg_std_Age', 'agg_std_Gender', 'agg_std_Color1', 'agg_std_Color2', \n",
    " 'agg_std_Color3', 'agg_std_FurLength', 'agg_std_Vaccinated', 'agg_std_Dewormed', 'agg_std_Sterilized',\n",
    " 'agg_std_Health', 'agg_std_Quantity', 'agg_std_Fee', 'agg_std_PhotoAmt', 'agg_std_VideoAmt', \n",
    "'average_word_length', 'num_words', 'desc_char_length', 'RescuerID_UNIQUE'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cols = ['Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14993, 155) (3972, 154)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape, test_df.shape)\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1067it [00:00, 10658.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000000it [01:43, 9658.09it/s]\n"
     ]
    }
   ],
   "source": [
    "print('getting embeddings')\n",
    "def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in tqdm(open('../input/fasttext-english-word-vectors-including-subwords/wiki-news-300d-1M-subword.vec', encoding= \"utf-8\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 200000\n",
    "maxlen = 200\n",
    "embed_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "train_df.loc[:, \"Description\"] = pd.read_csv(\"../input/petfinder-adoption-prediction/train/train.csv\")[\"Description\"]\n",
    "test_df.loc[:, \"Description\"] = pd.read_csv(\"../input/petfinder-adoption-prediction/test/test.csv\")[\"Description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "train_df['Description'] = train_df['Description'].astype(str).fillna('no text')\n",
    "test_df['Description'] = test_df['Description'].astype(str).fillna('no text')\n",
    "train_df['Description1'] = train_df['Description'].astype(str).fillna('no text')\n",
    "test_df['Description1'] = test_df['Description'].astype(str).fillna('no text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train_df['Description1'] = train_df['Description1'].astype(str).fillna('no text')\n",
    "test_df['Description1'] = test_df['Description1'].astype(str).fillna('no text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting tokenizer...\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitting tokenizer...\")\n",
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(train_df['Description'].values.tolist() + test_df['Description'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train_df['Description'] = tokenizer.texts_to_sequences(train_df['Description'])\n",
    "test_df['Description'] = tokenizer.texts_to_sequences(test_df['Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "avg_word_length = []\n",
    "desc_length = []\n",
    "number_words = []\n",
    "for desc in train_df[\"Description1\"]:\n",
    "    desc_length.append(len(desc))\n",
    "    words = desc.split()\n",
    "    number_words.append(len(words))\n",
    "    word_len = 0\n",
    "    for word in words:\n",
    "        word_len += len(word)\n",
    "    avg_word_length.append(word_len / len(words))\n",
    "train_df[\"average_word_length\"] = avg_word_length\n",
    "train_df[\"num_words\"] = number_words\n",
    "train_df[\"desc_char_length\"] = desc_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_word_length_test = []\n",
    "desc_length_test = []\n",
    "number_words_test = []\n",
    "for desc in test_df[\"Description1\"]:\n",
    "    desc_length_test.append(len(desc))\n",
    "    words = desc.split()\n",
    "    number_words_test.append(len(words))\n",
    "    word_len = 0\n",
    "    for word in words:\n",
    "        word_len += len(word)\n",
    "    avg_word_length_test.append(word_len / len(words))\n",
    "test_df[\"average_word_length\"] = avg_word_length_test\n",
    "test_df[\"num_words\"] = number_words_test\n",
    "test_df[\"desc_char_length\"] = desc_length_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "nb_words = min(num_words, len(word_index))\n",
    "embedding_matrix = np.zeros((nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= nb_words: \n",
    "        continue\n",
    "    try:\n",
    "        embedding_vector = embeddings_index[word]\n",
    "    except:\n",
    "        embedding_vector = None\n",
    "    if embedding_vector is not None: \n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train_df[col].tolist() + test_df[col].tolist())\n",
    "    train_df[col] = le.transform(train_df[col].tolist())\n",
    "    test_df[col] = le.transform(test_df[col].tolist())\n",
    "embed_sizes = [len(set(list(train_df[col].unique()) + list(test_df[col].unique()))) + 1 for col in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_list = [\"Age\", \"Gender\", \"FurLength\", \"Vaccinated\", \"Dewormed\", \"Sterilized\",\n",
    " \"Health\", \"Quantity\", \"Fee\", \"PhotoAmt\", \"VideoAmt\", \"Color1\", \"Color2\", \"Color3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "for col in agg_list:\n",
    "    means = train_df.groupby(\"RescuerID\")[col].mean()\n",
    "    train_df[\"agg_mean_\" + col] = train_df[\"RescuerID\"].map(means)\n",
    "    means = test_df.groupby(\"RescuerID\")[col].mean()\n",
    "    test_df[\"agg_mean_\" + col] = test_df[\"RescuerID\"].map(means)\n",
    "    num_cols.append(\"agg_mean_\" + col)\n",
    "for col in agg_list:\n",
    "    stds = train_df.groupby(\"RescuerID\")[col].std()\n",
    "    stds = stds.fillna(stds.mean())\n",
    "    train_df[\"agg_std_\" + col] = train_df[\"RescuerID\"].map(stds)\n",
    "    stds = test_df.groupby(\"RescuerID\")[col].std()\n",
    "    test_df[\"agg_std_\" + col] = test_df[\"RescuerID\"].map(stds)\n",
    "    num_cols.append(\"agg_std_\" + col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "train_df_copy = deepcopy(train_df)\n",
    "test_df_copy = deepcopy(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights loaded succesfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [02:57<00:00,  5.05it/s]\n",
      "100%|██████████| 249/249 [00:39<00:00,  5.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14993, 219) (3972, 218)\n"
     ]
    }
   ],
   "source": [
    "img_size = 256\n",
    "batch_size = 16\n",
    "pet_ids = train_df['PetID'].values\n",
    "n_batches = len(pet_ids) // batch_size + (len(pet_ids) % batch_size != 0)\n",
    "from keras.applications.densenet import preprocess_input, DenseNet121\n",
    "def resize_to_square(im):\n",
    "    old_size = im.shape[:2] # old_size is in (height, width) format\n",
    "    ratio = float(img_size)/max(old_size)\n",
    "    new_size = tuple([int(x*ratio) for x in old_size])\n",
    "    # new_size should be in (width, height) format\n",
    "    im = cv2.resize(im, (new_size[1], new_size[0]))\n",
    "    delta_w = img_size - new_size[1]\n",
    "    delta_h = img_size - new_size[0]\n",
    "    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "    left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "    color = [0, 0, 0]\n",
    "    new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,value=color)\n",
    "    return new_im\n",
    "\n",
    "def load_image(path, pet_id):\n",
    "    image = cv2.imread(f'{path}{pet_id}-1.jpg')\n",
    "    new_image = resize_to_square(image)\n",
    "    new_image = preprocess_input(new_image)\n",
    "    return new_image\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import GlobalAveragePooling2D, Input, Lambda, AveragePooling1D\n",
    "import keras.backend as K\n",
    "inp = Input((256,256,3))\n",
    "backbone = DenseNet121(input_tensor = inp, include_top = False, weights = None)\n",
    "backbone.load_weights(\"../input/densenet121weights/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\")\n",
    "print(\"weights loaded succesfully\")\n",
    "x = backbone.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Lambda(lambda x: K.expand_dims(x,axis = -1))(x)\n",
    "# x = AveragePooling1D(4)(x)\n",
    "out = Lambda(lambda x: x[:,:,0])(x)\n",
    "\n",
    "m = Model(inp,out)\n",
    "features = {}\n",
    "for b in tqdm(range(n_batches)):\n",
    "    start = b*batch_size\n",
    "    end = (b+1)*batch_size\n",
    "    batch_pets = pet_ids[start:end]\n",
    "    batch_images = np.zeros((len(batch_pets),img_size,img_size,3))\n",
    "    for i,pet_id in enumerate(batch_pets):\n",
    "        try:\n",
    "            batch_images[i] = load_image(\"../input/petfinder-adoption-prediction/train_images/\", pet_id)\n",
    "        except:\n",
    "            pass\n",
    "    batch_preds = m.predict(batch_images)\n",
    "    for i,pet_id in enumerate(batch_pets):\n",
    "        features[pet_id] = batch_preds[i]\n",
    "train_feats = pd.DataFrame.from_dict(features, orient='index').values\n",
    "n_components = 32\n",
    "svd = TruncatedSVD(n_components=n_components)\n",
    "svd.fit(train_feats)\n",
    "train_feats = svd.transform(train_feats)\n",
    "train_feats = pd.DataFrame(train_feats, columns=['img_svd1_{}'.format(i) for i in range(n_components)])\n",
    "train_feats.to_csv('train_img_features.csv')\n",
    "train_df = pd.concat([train_df, train_feats], axis = 1)\n",
    "\n",
    "## Test\n",
    "pet_ids = test_df['PetID'].values\n",
    "n_batches = len(pet_ids) // batch_size + (len(pet_ids) % batch_size != 0)\n",
    "features = {}\n",
    "for b in tqdm(range(n_batches)):\n",
    "    start = b*batch_size\n",
    "    end = (b+1)*batch_size\n",
    "    batch_pets = pet_ids[start:end]\n",
    "    batch_images = np.zeros((len(batch_pets),img_size,img_size,3))\n",
    "    for i,pet_id in enumerate(batch_pets):\n",
    "        try:\n",
    "            batch_images[i] = load_image(\"../input/petfinder-adoption-prediction/test_images/\", pet_id)\n",
    "        except:\n",
    "            pass\n",
    "    batch_preds = m.predict(batch_images)\n",
    "    for i,pet_id in enumerate(batch_pets):\n",
    "        features[pet_id] = batch_preds[i]\n",
    "test_feats = pd.DataFrame.from_dict(features, orient='index').values\n",
    "test_feats = svd.transform(test_feats)\n",
    "test_feats = pd.DataFrame(test_feats, columns=['img_svd1_{}'.format(i) for i in range(n_components)])\n",
    "test_feats.to_csv('test_img_features.csv')\n",
    "test_df = pd.concat((test_df.reset_index(drop = True), test_feats), axis=1)\n",
    "\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "catvsdog = load_model(\"../input/kerascatvsdog/best.hd5\")\n",
    "img_size = 299\n",
    "batch_size = 16\n",
    "pet_ids = train_df['PetID'].values\n",
    "n_batches = len(pet_ids) // batch_size + (len(pet_ids) % batch_size != 0)\n",
    "from keras.applications.densenet import preprocess_input, DenseNet121\n",
    "def resize_to_square(im):\n",
    "    old_size = im.shape[:2] # old_size is in (height, width) format\n",
    "    ratio = float(img_size)/max(old_size)\n",
    "    new_size = tuple([int(x*ratio) for x in old_size])\n",
    "    # new_size should be in (width, height) format\n",
    "    im = cv2.resize(im, (new_size[1], new_size[0]))\n",
    "    delta_w = img_size - new_size[1]\n",
    "    delta_h = img_size - new_size[0]\n",
    "    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "    left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "    color = [0, 0, 0]\n",
    "    new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,value=color)\n",
    "    return new_im\n",
    "\n",
    "def load_image(path, pet_id):\n",
    "    image = cv2.imread(f'{path}{pet_id}-1.jpg')\n",
    "    new_image = resize_to_square(image)\n",
    "    new_image = preprocess_input(new_image)\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [03:01<00:00,  4.64it/s]\n",
      "100%|██████████| 249/249 [00:41<00:00,  4.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14993, 251) (3972, 250)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import GlobalAveragePooling2D, Input, Lambda, AveragePooling1D\n",
    "import keras.backend as K\n",
    "backbone = catvsdog\n",
    "out = backbone.layers[-2].output\n",
    "\n",
    "\n",
    "m = Model(backbone.input, out)\n",
    "features = {}\n",
    "for b in tqdm(range(n_batches)):\n",
    "    start = b*batch_size\n",
    "    end = (b+1)*batch_size\n",
    "    batch_pets = pet_ids[start:end]\n",
    "    batch_images = np.zeros((len(batch_pets),img_size,img_size,3))\n",
    "    for i,pet_id in enumerate(batch_pets):\n",
    "        try:\n",
    "            batch_images[i] = load_image(\"../input/petfinder-adoption-prediction/train_images/\", pet_id)\n",
    "        except:\n",
    "            pass\n",
    "    batch_preds = m.predict(batch_images)\n",
    "    for i,pet_id in enumerate(batch_pets):\n",
    "        features[pet_id] = batch_preds[i]\n",
    "train_feats = pd.DataFrame.from_dict(features, orient='index').values\n",
    "n_components = 32\n",
    "svd = TruncatedSVD(n_components=n_components)\n",
    "svd.fit(train_feats)\n",
    "train_feats = svd.transform(train_feats)\n",
    "train_feats = pd.DataFrame(train_feats, columns=['img_svd2_{}'.format(i) for i in range(n_components)])\n",
    "train_feats.to_csv('train_img_features.csv')\n",
    "train_df = pd.concat([train_df, train_feats], axis = 1)\n",
    "pet_ids = test_df['PetID'].values\n",
    "n_batches = len(pet_ids) // batch_size + 1\n",
    "features = {}\n",
    "for b in tqdm(range(n_batches)):\n",
    "    start = b*batch_size\n",
    "    end = (b+1)*batch_size\n",
    "    batch_pets = pet_ids[start:end]\n",
    "    batch_images = np.zeros((len(batch_pets),img_size,img_size,3))\n",
    "    for i,pet_id in enumerate(batch_pets):\n",
    "        try:\n",
    "            batch_images[i] = load_image(\"../input/petfinder-adoption-prediction/test_images/\", pet_id)\n",
    "        except:\n",
    "            pass\n",
    "    batch_preds = m.predict(batch_images)\n",
    "    for i,pet_id in enumerate(batch_pets):\n",
    "        features[pet_id] = batch_preds[i]\n",
    "test_feats = pd.DataFrame.from_dict(features, orient='index').values\n",
    "test_feats = svd.transform(test_feats)\n",
    "test_feats = pd.DataFrame(test_feats, columns=['img_svd2_{}'.format(i) for i in range(n_components)])\n",
    "test_feats.to_csv('test_img_features.csv')\n",
    "test_df = pd.concat((test_df.reset_index(drop = True), test_feats), axis=1)\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3972,)\n",
      "(3972, 282)\n"
     ]
    }
   ],
   "source": [
    "n_components = 32\n",
    "train_desc = train_df.Description1.fillna(\"none\").values\n",
    "test_desc = test_df.Description1.fillna(\"none\").values\n",
    "print(test_desc.shape)\n",
    "tfv = TfidfVectorizer(min_df=50,  max_features=None,\n",
    "        strip_accents='unicode', analyzer='word', token_pattern=r'(?u)\\b\\w+\\b',\n",
    "        ngram_range=(1, 3), use_idf=1, smooth_idf=1, sublinear_tf=1,\n",
    "        )\n",
    "    \n",
    "# Fit TFIDF\n",
    "tfv.fit(list(train_desc))\n",
    "X =  tfv.transform(train_desc)\n",
    "X_test = tfv.transform(test_desc)\n",
    "\n",
    "svd = TruncatedSVD(n_components=n_components)\n",
    "svd.fit(X)\n",
    "X = svd.transform(X)\n",
    "X = pd.DataFrame(X, columns=['svd1_{}'.format(i) for i in range(n_components)])\n",
    "train_df = pd.concat((train_df, X), axis=1)\n",
    "X_test = svd.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test, columns=['svd1_{}'.format(i) for i in range(n_components)])\n",
    "test_df = pd.concat((test_df.reset_index(drop = True), X_test), axis=1)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "split_char = '/'\n",
    "train_df_ids = train_df[['PetID']]\n",
    "test_df_ids = test_df[['PetID']]\n",
    "\n",
    "train_df_imgs = pd.DataFrame(train_image_files)\n",
    "train_df_imgs.columns = ['image_filename']\n",
    "train_imgs_pets = train_df_imgs['image_filename'].apply(lambda x: x.split(split_char)[-1].split('-')[0])\n",
    "\n",
    "test_df_imgs = pd.DataFrame(test_image_files)\n",
    "test_df_imgs.columns = ['image_filename']\n",
    "test_imgs_pets = test_df_imgs['image_filename'].apply(lambda x: x.split(split_char)[-1].split('-')[0])\n",
    "\n",
    "train_df_imgs = train_df_imgs.assign(PetID=train_imgs_pets)\n",
    "test_df_imgs = test_df_imgs.assign(PetID=test_imgs_pets)\n",
    "\n",
    "def getSize(filename):\n",
    "    st = os.stat(filename)\n",
    "    return st.st_size\n",
    "\n",
    "def getDimensions(filename):\n",
    "    img_size = Image.open(filename).size\n",
    "    return img_size \n",
    "\n",
    "train_df_imgs['image_size'] = train_df_imgs['image_filename'].apply(getSize)\n",
    "train_df_imgs['temp_size'] = train_df_imgs['image_filename'].apply(getDimensions)\n",
    "train_df_imgs['width'] = train_df_imgs['temp_size'].apply(lambda x : x[0])\n",
    "train_df_imgs['height'] = train_df_imgs['temp_size'].apply(lambda x : x[1])\n",
    "train_df_imgs = train_df_imgs.drop(['temp_size'], axis=1)\n",
    "\n",
    "test_df_imgs['image_size'] = test_df_imgs['image_filename'].apply(getSize)\n",
    "test_df_imgs['temp_size'] = test_df_imgs['image_filename'].apply(getDimensions)\n",
    "test_df_imgs['width'] = test_df_imgs['temp_size'].apply(lambda x : x[0])\n",
    "test_df_imgs['height'] = test_df_imgs['temp_size'].apply(lambda x : x[1])\n",
    "test_df_imgs = test_df_imgs.drop(['temp_size'], axis=1)\n",
    "\n",
    "aggs = {\n",
    "    'image_size': ['sum', 'mean', 'var'],\n",
    "    'width': ['sum', 'mean', 'var'],\n",
    "    'height': ['sum', 'mean', 'var'],\n",
    "}\n",
    "\n",
    "agg_train_imgs = train_df_imgs.groupby('PetID').agg(aggs)\n",
    "new_columns = [\n",
    "    k + '_' + agg for k in aggs.keys() for agg in aggs[k]\n",
    "]\n",
    "agg_train_imgs.columns = new_columns\n",
    "agg_train_imgs = agg_train_imgs.reset_index()\n",
    "\n",
    "agg_test_imgs = test_df_imgs.groupby('PetID').agg(aggs)\n",
    "new_columns = [\n",
    "    k + '_' + agg for k in aggs.keys() for agg in aggs[k]\n",
    "]\n",
    "agg_test_imgs.columns = new_columns\n",
    "agg_test_imgs = agg_test_imgs.reset_index()\n",
    "\n",
    "train_df = train_df.merge(agg_train_imgs, how='left', on='PetID')\n",
    "test_df = test_df.merge(agg_test_imgs, how='left', on='PetID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "def get_input_features(df):\n",
    "    nn_nums= [x for x in list(num_cols) #if x not in list(no_scale_cols)\n",
    "             ]\n",
    "    X = {'description':pad_sequences(df['Description'], maxlen=maxlen)}\n",
    "    X['numerical'] = np.array(df[nn_nums])\n",
    "    X['bow_inputs'] = np.array(df[list([\"svd1_\" + str(i) for i in range(n_components)] + \n",
    "                                       [\"SVD_metadata_annots_top_desc_\" + str(i) for i in range(16)] +\n",
    "                                       [\"SVD_sentiment_entities_\" + str(i) for i in range(16)]\n",
    "                                     )])\n",
    "    X['img_inputs'] = np.array(df[list([\"img_svd1_\" + str(i) for i in range(n_components)] + [\"img_svd2_\" + str(i) for i in range(n_components)]\n",
    "                                     )])\n",
    "    for cat in cat_cols:\n",
    "        X[cat] = np.array(df[cat])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "\n",
    "from collections import Counter\n",
    "from functools import partial\n",
    "from math import sqrt\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score, mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix as sk_cmatrix\n",
    "\n",
    "\n",
    "# FROM: https://www.kaggle.com/myltykritik/simple-lgbm-image-features\n",
    "\n",
    "# The following 3 functions have been taken from Ben Hamner's github repository\n",
    "# https://github.com/benhamner/Metrics\n",
    "def confusion_matrix(rater_a, rater_b, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Returns the confusion matrix between rater's ratings\n",
    "    \"\"\"\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(rater_a + rater_b)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(rater_a + rater_b)\n",
    "    num_ratings = int(max_rating - min_rating + 1)\n",
    "    conf_mat = [[0 for i in range(num_ratings)]\n",
    "                for j in range(num_ratings)]\n",
    "    for a, b in zip(rater_a, rater_b):\n",
    "        conf_mat[a - min_rating][b - min_rating] += 1\n",
    "    return conf_mat\n",
    "\n",
    "\n",
    "def histogram(ratings, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Returns the counts of each type of rating that a rater made\n",
    "    \"\"\"\n",
    "    if min_rating is None:\n",
    "        min_rating = min(ratings)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(ratings)\n",
    "    num_ratings = int(max_rating - min_rating + 1)\n",
    "    hist_ratings = [0 for x in range(num_ratings)]\n",
    "    for r in ratings:\n",
    "        hist_ratings[r - min_rating] += 1\n",
    "    return hist_ratings\n",
    "\n",
    "\n",
    "def quadratic_weighted_kappa(y, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the quadratic weighted kappa\n",
    "    axquadratic_weighted_kappa calculates the quadratic weighted kappa\n",
    "    value, which is a measure of inter-rater agreement between two raters\n",
    "    that provide discrete numeric ratings.  Potential values range from -1\n",
    "    (representing complete disagreement) to 1 (representing complete\n",
    "    agreement).  A kappa value of 0 is expected if all agreement is due to\n",
    "    chance.\n",
    "    quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n",
    "    each correspond to a list of integer ratings.  These lists must have the\n",
    "    same length.\n",
    "    The ratings should be integers, and it is assumed that they contain\n",
    "    the complete range of possible ratings.\n",
    "    quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n",
    "    is the minimum possible rating, and max_rating is the maximum possible\n",
    "    rating\n",
    "    \"\"\"\n",
    "    rater_a = y\n",
    "    rater_b = y_pred\n",
    "    min_rating=None\n",
    "    max_rating=None\n",
    "    rater_a = np.array(rater_a, dtype=int)\n",
    "    rater_b = np.array(rater_b, dtype=int)\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(min(rater_a), min(rater_b))\n",
    "    if max_rating is None:\n",
    "        max_rating = max(max(rater_a), max(rater_b))\n",
    "    conf_mat = confusion_matrix(rater_a, rater_b,\n",
    "                                min_rating, max_rating)\n",
    "    num_ratings = len(conf_mat)\n",
    "    num_scored_items = float(len(rater_a))\n",
    "\n",
    "    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n",
    "    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n",
    "\n",
    "    numerator = 0.0\n",
    "    denominator = 0.0\n",
    "\n",
    "    for i in range(num_ratings):\n",
    "        for j in range(num_ratings):\n",
    "            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n",
    "                              / num_scored_items)\n",
    "            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n",
    "            numerator += d * conf_mat[i][j] / num_scored_items\n",
    "            denominator += d * expected_count / num_scored_items\n",
    "\n",
    "    return (1.0 - numerator / denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put numerical value to one of bins\n",
    "def to_bins(x, borders):\n",
    "    for i in range(len(borders)):\n",
    "        if x <= borders[i]:\n",
    "            return i\n",
    "    return len(borders)\n",
    "\n",
    "class OptimizedRounder(object):\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _loss(self, coef, X, y, idx):\n",
    "        X_p = np.array([to_bins(pred, coef) for pred in X])\n",
    "        ll = -quadratic_weighted_kappa(y, X_p)\n",
    "        return ll\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        coef = [1.5, 2.0, 2.5, 3.0]\n",
    "        golden1 = 0.618\n",
    "        golden2 = 1 - golden1\n",
    "        ab_start = [(1, 2), (1.5, 2.5), (2, 3), (2.5, 3.5)]\n",
    "        for it1 in range(10):\n",
    "            for idx in range(4):\n",
    "                # golden section search\n",
    "                a, b = ab_start[idx]\n",
    "                # calc losses\n",
    "                coef[idx] = a\n",
    "                la = self._loss(coef, X, y, idx)\n",
    "                coef[idx] = b\n",
    "                lb = self._loss(coef, X, y, idx)\n",
    "                for it in range(20):\n",
    "                    # choose value\n",
    "                    if la > lb:\n",
    "                        a = b - (b - a) * golden1\n",
    "                        coef[idx] = a\n",
    "                        la = self._loss(coef, X, y, idx)\n",
    "                    else:\n",
    "                        b = b - (b - a) * golden2\n",
    "                        coef[idx] = b\n",
    "                        lb = self._loss(coef, X, y, idx)\n",
    "        self.coef_ = {'x': coef}\n",
    "\n",
    "    def predict(self, X, coef):\n",
    "        X_p = np.array([to_bins(pred, coef) for pred in X])\n",
    "        return X_p\n",
    "\n",
    "    def coefficients(self):\n",
    "        return self.coef_['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, Concatenate, Flatten, Dense, Dropout, BatchNormalization, CuDNNLSTM, SpatialDropout1D\n",
    "from keras.layers import Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D, Conv1D, MaxPool1D, concatenate\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.models import Model\n",
    "from keras.optimizers import  Adam\n",
    "import keras.backend as k\n",
    "def make_model(softmax = False):\n",
    "    k.clear_session()\n",
    "\n",
    "    categorical_inputs = []\n",
    "    for cat in cat_cols:\n",
    "        categorical_inputs.append(Input(shape=[1], name=cat))\n",
    "\n",
    "    categorical_embeddings = []\n",
    "    for i, cat in enumerate(cat_cols):\n",
    "        categorical_embeddings.append(\n",
    "            Embedding(embed_sizes[i], 10, name = cat + \"_embed\")(categorical_inputs[i]))\n",
    "\n",
    "    categorical_logits = Concatenate()([Flatten()(cat_emb) for cat_emb in categorical_embeddings])\n",
    "    categorical_logits = Dropout(.5)(categorical_logits)\n",
    "    categorical_logits = Dense(50, activation = 'relu')(categorical_logits)\n",
    "\n",
    "    numerical_inputs = Input(shape=[X_train[\"numerical\"].shape[1]], name = 'numerical')\n",
    "    numerical_logits = Dropout(.2)(numerical_inputs)\n",
    "    numerical_logits = Dense(50, activation = 'relu')(numerical_logits)\n",
    "    numerical_logits = Dense(50, activation = 'relu')(numerical_logits)\n",
    "    \n",
    "    img_inputs = Input(shape = [n_components * 2], name = \"img_inputs\")\n",
    "    img_logits = Dropout(.2)(img_inputs)\n",
    "    \n",
    "    bow_inputs = Input(shape = [n_components * 2], name = \"bow_inputs\")\n",
    "    bow_logits = Dropout(.2)(bow_inputs)\n",
    "    \n",
    "\n",
    "    text_inp = Input(shape=[maxlen], name='description')\n",
    "    text_embed = Embedding(nb_words, embed_size, weights=[embedding_matrix], trainable=False)(text_inp)\n",
    "    emb_desc = SpatialDropout1D(.6)(text_embed)\n",
    "    filter_sizes=[1,2,3,4]\n",
    "    convs = []\n",
    "    for filter_size in filter_sizes:\n",
    "        conv = Conv1D(8, kernel_size=(filter_size), \n",
    "                        kernel_initializer=\"normal\", activation=\"relu\")(emb_desc)\n",
    "        convs.append(MaxPool1D(pool_size=(maxlen-filter_size+1))(conv))\n",
    "    text_logits = concatenate(convs)\n",
    "    avg_pool = GlobalAveragePooling1D()(text_logits)\n",
    "    max_pool = GlobalMaxPooling1D()(text_logits)\n",
    "    text_logits = Concatenate()([avg_pool, max_pool])     \n",
    "        \n",
    "\n",
    "    x = Concatenate()([\n",
    "        bow_logits,\n",
    "        categorical_logits, \n",
    "        text_logits, \n",
    "        numerical_logits,\n",
    "        img_logits\n",
    "    ])\n",
    "    x = Dense(300, activation = 'relu')(x)\n",
    "    x = Dropout(.2)(x)\n",
    "    x = Dense(200, activation = 'relu')(x)\n",
    "    x = Dropout(.2)(x)\n",
    "    x = Dense(100, activation = 'relu')(x)\n",
    "    \n",
    "    if softmax == True:\n",
    "        out = Dense(5, activation = 'softmax')(x)\n",
    "    else:\n",
    "        out = Dense(1, activation = 'sigmoid')(x)\n",
    "    \n",
    "\n",
    "    model = Model(inputs=[text_inp] + categorical_inputs + [numerical_inputs] + [bow_inputs] + [img_inputs],outputs=out)\n",
    "    if softmax == True:\n",
    "        loss = kappa_loss\n",
    "    else:\n",
    "        loss = root_mean_squared_error\n",
    "    model.compile(optimizer=Adam(lr = 0.0005), loss = loss)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescuerID = pd.read_csv(\"../input/petfinder-adoption-prediction/train/train.csv\")[\"RescuerID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 13493 samples, validate on 1500 samples\n",
      "Epoch 1/35\n",
      " - 2s - loss: 0.3111 - val_loss: 0.2732\n",
      "Epoch 2/35\n",
      " - 1s - loss: 0.2918 - val_loss: 0.2726\n",
      "Epoch 3/35\n",
      " - 1s - loss: 0.2885 - val_loss: 0.2731\n",
      "Epoch 4/35\n",
      " - 1s - loss: 0.2872 - val_loss: 0.2720\n",
      "Epoch 5/35\n",
      " - 1s - loss: 0.2862 - val_loss: 0.2760\n",
      "Epoch 6/35\n",
      " - 1s - loss: 0.2845 - val_loss: 0.2711\n",
      "Epoch 7/35\n",
      " - 1s - loss: 0.2835 - val_loss: 0.2727\n",
      "Epoch 8/35\n",
      " - 1s - loss: 0.2825 - val_loss: 0.2707\n",
      "Epoch 9/35\n",
      " - 1s - loss: 0.2818 - val_loss: 0.2709\n",
      "Epoch 10/35\n",
      " - 1s - loss: 0.2805 - val_loss: 0.2730\n",
      "Epoch 11/35\n",
      " - 1s - loss: 0.2790 - val_loss: 0.2731\n",
      "Epoch 12/35\n",
      " - 1s - loss: 0.2776 - val_loss: 0.2713\n",
      "Epoch 13/35\n",
      " - 1s - loss: 0.2785 - val_loss: 0.2733\n",
      "Epoch 14/35\n",
      " - 1s - loss: 0.2759 - val_loss: 0.2713\n",
      "Epoch 15/35\n",
      " - 1s - loss: 0.2756 - val_loss: 0.2713\n",
      "Epoch 16/35\n",
      " - 1s - loss: 0.2752 - val_loss: 0.2701\n",
      "Epoch 17/35\n",
      " - 1s - loss: 0.2748 - val_loss: 0.2728\n",
      "Epoch 18/35\n",
      " - 1s - loss: 0.2741 - val_loss: 0.2712\n",
      "Epoch 19/35\n",
      " - 1s - loss: 0.2727 - val_loss: 0.2718\n",
      "Epoch 20/35\n",
      " - 1s - loss: 0.2722 - val_loss: 0.2714\n",
      "Epoch 21/35\n",
      " - 1s - loss: 0.2724 - val_loss: 0.2706\n",
      "Epoch 22/35\n",
      " - 1s - loss: 0.2722 - val_loss: 0.2713\n",
      "Epoch 23/35\n",
      " - 1s - loss: 0.2720 - val_loss: 0.2715\n",
      "Epoch 24/35\n",
      " - 1s - loss: 0.2709 - val_loss: 0.2715\n",
      "Epoch 25/35\n",
      " - 1s - loss: 0.2709 - val_loss: 0.2725\n",
      "Epoch 26/35\n",
      " - 1s - loss: 0.2709 - val_loss: 0.2705\n",
      "Epoch 27/35\n",
      " - 1s - loss: 0.2703 - val_loss: 0.2711\n",
      "Epoch 28/35\n",
      " - 1s - loss: 0.2695 - val_loss: 0.2705\n",
      "Epoch 29/35\n",
      " - 1s - loss: 0.2698 - val_loss: 0.2710\n",
      "Epoch 30/35\n",
      " - 1s - loss: 0.2695 - val_loss: 0.2710\n",
      "Epoch 31/35\n",
      " - 1s - loss: 0.2691 - val_loss: 0.2714\n",
      "Epoch 32/35\n",
      " - 1s - loss: 0.2683 - val_loss: 0.2720\n",
      "Epoch 33/35\n",
      " - 1s - loss: 0.2677 - val_loss: 0.2715\n",
      "Epoch 34/35\n",
      " - 1s - loss: 0.2680 - val_loss: 0.2717\n",
      "Epoch 35/35\n",
      " - 1s - loss: 0.2677 - val_loss: 0.2720\n",
      "Train on 13493 samples, validate on 1500 samples\n",
      "Epoch 1/35\n",
      " - 2s - loss: 0.3144 - val_loss: 0.2847\n",
      "Epoch 2/35\n",
      " - 1s - loss: 0.2909 - val_loss: 0.2805\n",
      "Epoch 3/35\n",
      " - 1s - loss: 0.2887 - val_loss: 0.2827\n",
      "Epoch 4/35\n",
      " - 1s - loss: 0.2857 - val_loss: 0.2811\n",
      "Epoch 5/35\n",
      " - 1s - loss: 0.2836 - val_loss: 0.2779\n",
      "Epoch 6/35\n",
      " - 1s - loss: 0.2836 - val_loss: 0.2773\n",
      "Epoch 7/35\n",
      " - 1s - loss: 0.2828 - val_loss: 0.2765\n",
      "Epoch 8/35\n",
      " - 1s - loss: 0.2823 - val_loss: 0.2770\n",
      "Epoch 9/35\n",
      " - 1s - loss: 0.2795 - val_loss: 0.2754\n",
      "Epoch 10/35\n",
      " - 1s - loss: 0.2791 - val_loss: 0.2768\n",
      "Epoch 11/35\n",
      " - 1s - loss: 0.2773 - val_loss: 0.2751\n",
      "Epoch 12/35\n",
      " - 1s - loss: 0.2766 - val_loss: 0.2739\n",
      "Epoch 13/35\n",
      " - 1s - loss: 0.2761 - val_loss: 0.2730\n",
      "Epoch 14/35\n",
      " - 1s - loss: 0.2751 - val_loss: 0.2734\n",
      "Epoch 15/35\n",
      " - 1s - loss: 0.2740 - val_loss: 0.2725\n",
      "Epoch 16/35\n",
      " - 1s - loss: 0.2742 - val_loss: 0.2743\n",
      "Epoch 17/35\n",
      " - 1s - loss: 0.2740 - val_loss: 0.2752\n",
      "Epoch 18/35\n",
      " - 1s - loss: 0.2724 - val_loss: 0.2719\n",
      "Epoch 19/35\n",
      " - 1s - loss: 0.2724 - val_loss: 0.2725\n",
      "Epoch 20/35\n",
      " - 1s - loss: 0.2714 - val_loss: 0.2718\n",
      "Epoch 21/35\n",
      " - 1s - loss: 0.2709 - val_loss: 0.2735\n",
      "Epoch 22/35\n",
      " - 1s - loss: 0.2702 - val_loss: 0.2733\n",
      "Epoch 23/35\n",
      " - 1s - loss: 0.2697 - val_loss: 0.2733\n",
      "Epoch 24/35\n",
      " - 1s - loss: 0.2697 - val_loss: 0.2741\n",
      "Epoch 25/35\n",
      " - 1s - loss: 0.2687 - val_loss: 0.2739\n",
      "Epoch 26/35\n",
      " - 1s - loss: 0.2679 - val_loss: 0.2733\n",
      "Epoch 27/35\n",
      " - 1s - loss: 0.2680 - val_loss: 0.2743\n",
      "Epoch 28/35\n",
      " - 1s - loss: 0.2672 - val_loss: 0.2720\n",
      "Epoch 29/35\n",
      " - 1s - loss: 0.2678 - val_loss: 0.2729\n",
      "Epoch 30/35\n",
      " - 1s - loss: 0.2667 - val_loss: 0.2732\n",
      "Epoch 31/35\n",
      " - 1s - loss: 0.2669 - val_loss: 0.2738\n",
      "Epoch 32/35\n",
      " - 1s - loss: 0.2659 - val_loss: 0.2754\n",
      "Epoch 33/35\n",
      " - 1s - loss: 0.2657 - val_loss: 0.2735\n",
      "Epoch 34/35\n",
      " - 1s - loss: 0.2650 - val_loss: 0.2727\n",
      "Epoch 35/35\n",
      " - 1s - loss: 0.2662 - val_loss: 0.2732\n",
      "Train on 13493 samples, validate on 1500 samples\n",
      "Epoch 1/35\n",
      " - 2s - loss: 0.3111 - val_loss: 0.2828\n",
      "Epoch 2/35\n",
      " - 1s - loss: 0.2900 - val_loss: 0.2766\n",
      "Epoch 3/35\n",
      " - 1s - loss: 0.2877 - val_loss: 0.2762\n",
      "Epoch 4/35\n",
      " - 1s - loss: 0.2857 - val_loss: 0.2734\n",
      "Epoch 5/35\n",
      " - 1s - loss: 0.2850 - val_loss: 0.2731\n",
      "Epoch 6/35\n",
      " - 1s - loss: 0.2841 - val_loss: 0.2739\n",
      "Epoch 7/35\n",
      " - 1s - loss: 0.2830 - val_loss: 0.2713\n",
      "Epoch 8/35\n",
      " - 1s - loss: 0.2823 - val_loss: 0.2730\n",
      "Epoch 9/35\n",
      " - 1s - loss: 0.2810 - val_loss: 0.2720\n",
      "Epoch 10/35\n",
      " - 1s - loss: 0.2783 - val_loss: 0.2703\n",
      "Epoch 11/35\n",
      " - 1s - loss: 0.2787 - val_loss: 0.2692\n",
      "Epoch 12/35\n",
      " - 1s - loss: 0.2770 - val_loss: 0.2703\n",
      "Epoch 13/35\n",
      " - 1s - loss: 0.2763 - val_loss: 0.2691\n",
      "Epoch 14/35\n",
      " - 1s - loss: 0.2758 - val_loss: 0.2703\n",
      "Epoch 15/35\n",
      " - 1s - loss: 0.2753 - val_loss: 0.2680\n",
      "Epoch 16/35\n",
      " - 1s - loss: 0.2745 - val_loss: 0.2688\n",
      "Epoch 17/35\n",
      " - 1s - loss: 0.2742 - val_loss: 0.2690\n",
      "Epoch 18/35\n",
      " - 1s - loss: 0.2728 - val_loss: 0.2681\n",
      "Epoch 19/35\n",
      " - 1s - loss: 0.2722 - val_loss: 0.2706\n",
      "Epoch 20/35\n",
      " - 1s - loss: 0.2723 - val_loss: 0.2678\n",
      "Epoch 21/35\n",
      " - 1s - loss: 0.2712 - val_loss: 0.2686\n",
      "Epoch 22/35\n",
      " - 1s - loss: 0.2707 - val_loss: 0.2675\n",
      "Epoch 23/35\n",
      " - 1s - loss: 0.2708 - val_loss: 0.2710\n",
      "Epoch 24/35\n",
      " - 1s - loss: 0.2702 - val_loss: 0.2686\n",
      "Epoch 25/35\n",
      " - 1s - loss: 0.2699 - val_loss: 0.2698\n",
      "Epoch 26/35\n",
      " - 1s - loss: 0.2685 - val_loss: 0.2695\n",
      "Epoch 27/35\n",
      " - 1s - loss: 0.2692 - val_loss: 0.2690\n",
      "Epoch 28/35\n",
      " - 1s - loss: 0.2677 - val_loss: 0.2685\n",
      "Epoch 29/35\n",
      " - 1s - loss: 0.2659 - val_loss: 0.2698\n",
      "Epoch 30/35\n",
      " - 1s - loss: 0.2666 - val_loss: 0.2682\n",
      "Epoch 31/35\n",
      " - 1s - loss: 0.2666 - val_loss: 0.2685\n",
      "Epoch 32/35\n",
      " - 1s - loss: 0.2669 - val_loss: 0.2691\n",
      "Epoch 33/35\n",
      " - 1s - loss: 0.2654 - val_loss: 0.2690\n",
      "Epoch 34/35\n",
      " - 1s - loss: 0.2659 - val_loss: 0.2691\n",
      "Epoch 35/35\n",
      " - 1s - loss: 0.2646 - val_loss: 0.2686\n",
      "Train on 13494 samples, validate on 1499 samples\n",
      "Epoch 1/35\n",
      " - 2s - loss: 0.3134 - val_loss: 0.2917\n",
      "Epoch 2/35\n",
      " - 1s - loss: 0.2904 - val_loss: 0.2901\n",
      "Epoch 3/35\n",
      " - 1s - loss: 0.2884 - val_loss: 0.2829\n",
      "Epoch 4/35\n",
      " - 1s - loss: 0.2863 - val_loss: 0.2854\n",
      "Epoch 5/35\n",
      " - 1s - loss: 0.2848 - val_loss: 0.2817\n",
      "Epoch 6/35\n",
      " - 1s - loss: 0.2836 - val_loss: 0.2849\n",
      "Epoch 7/35\n",
      " - 1s - loss: 0.2835 - val_loss: 0.2834\n",
      "Epoch 8/35\n",
      " - 1s - loss: 0.2819 - val_loss: 0.2806\n",
      "Epoch 9/35\n",
      " - 1s - loss: 0.2803 - val_loss: 0.2780\n",
      "Epoch 10/35\n",
      " - 1s - loss: 0.2790 - val_loss: 0.2763\n",
      "Epoch 11/35\n",
      " - 1s - loss: 0.2788 - val_loss: 0.2769\n",
      "Epoch 12/35\n",
      " - 1s - loss: 0.2770 - val_loss: 0.2761\n",
      "Epoch 13/35\n",
      " - 1s - loss: 0.2773 - val_loss: 0.2756\n",
      "Epoch 14/35\n",
      " - 1s - loss: 0.2764 - val_loss: 0.2754\n",
      "Epoch 15/35\n",
      " - 1s - loss: 0.2762 - val_loss: 0.2731\n",
      "Epoch 16/35\n",
      " - 1s - loss: 0.2745 - val_loss: 0.2725\n",
      "Epoch 17/35\n",
      " - 1s - loss: 0.2740 - val_loss: 0.2740\n",
      "Epoch 18/35\n",
      " - 1s - loss: 0.2741 - val_loss: 0.2729\n",
      "Epoch 19/35\n",
      " - 1s - loss: 0.2731 - val_loss: 0.2731\n",
      "Epoch 20/35\n",
      " - 1s - loss: 0.2728 - val_loss: 0.2708\n",
      "Epoch 21/35\n",
      " - 1s - loss: 0.2727 - val_loss: 0.2716\n",
      "Epoch 22/35\n",
      " - 1s - loss: 0.2711 - val_loss: 0.2710\n",
      "Epoch 23/35\n",
      " - 1s - loss: 0.2708 - val_loss: 0.2721\n",
      "Epoch 24/35\n",
      " - 1s - loss: 0.2713 - val_loss: 0.2720\n",
      "Epoch 25/35\n",
      " - 1s - loss: 0.2712 - val_loss: 0.2697\n",
      "Epoch 26/35\n",
      " - 1s - loss: 0.2705 - val_loss: 0.2698\n",
      "Epoch 27/35\n",
      " - 1s - loss: 0.2701 - val_loss: 0.2703\n",
      "Epoch 28/35\n",
      " - 1s - loss: 0.2688 - val_loss: 0.2692\n",
      "Epoch 29/35\n",
      " - 1s - loss: 0.2699 - val_loss: 0.2696\n",
      "Epoch 30/35\n",
      " - 1s - loss: 0.2685 - val_loss: 0.2694\n",
      "Epoch 31/35\n",
      " - 1s - loss: 0.2678 - val_loss: 0.2693\n",
      "Epoch 32/35\n",
      " - 1s - loss: 0.2679 - val_loss: 0.2703\n",
      "Epoch 33/35\n",
      " - 1s - loss: 0.2675 - val_loss: 0.2695\n",
      "Epoch 34/35\n",
      " - 1s - loss: 0.2667 - val_loss: 0.2701\n",
      "Epoch 35/35\n",
      " - 1s - loss: 0.2659 - val_loss: 0.2693\n",
      "Train on 13494 samples, validate on 1499 samples\n",
      "Epoch 1/35\n",
      " - 2s - loss: 0.3181 - val_loss: 0.2861\n",
      "Epoch 2/35\n",
      " - 1s - loss: 0.2914 - val_loss: 0.2837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/35\n",
      " - 1s - loss: 0.2883 - val_loss: 0.2839\n",
      "Epoch 4/35\n",
      " - 1s - loss: 0.2863 - val_loss: 0.2830\n",
      "Epoch 5/35\n",
      " - 1s - loss: 0.2854 - val_loss: 0.2854\n",
      "Epoch 6/35\n",
      " - 1s - loss: 0.2835 - val_loss: 0.2851\n",
      "Epoch 7/35\n",
      " - 1s - loss: 0.2825 - val_loss: 0.2785\n",
      "Epoch 8/35\n",
      " - 1s - loss: 0.2819 - val_loss: 0.2809\n",
      "Epoch 9/35\n",
      " - 1s - loss: 0.2821 - val_loss: 0.2837\n",
      "Epoch 10/35\n",
      " - 1s - loss: 0.2790 - val_loss: 0.2768\n",
      "Epoch 11/35\n",
      " - 1s - loss: 0.2795 - val_loss: 0.2766\n",
      "Epoch 12/35\n",
      " - 1s - loss: 0.2777 - val_loss: 0.2755\n",
      "Epoch 13/35\n",
      " - 1s - loss: 0.2771 - val_loss: 0.2789\n",
      "Epoch 14/35\n",
      " - 1s - loss: 0.2761 - val_loss: 0.2746\n",
      "Epoch 15/35\n",
      " - 1s - loss: 0.2749 - val_loss: 0.2728\n",
      "Epoch 16/35\n",
      " - 1s - loss: 0.2751 - val_loss: 0.2765\n",
      "Epoch 17/35\n",
      " - 1s - loss: 0.2735 - val_loss: 0.2743\n",
      "Epoch 18/35\n",
      " - 1s - loss: 0.2738 - val_loss: 0.2738\n",
      "Epoch 19/35\n",
      " - 1s - loss: 0.2726 - val_loss: 0.2736\n",
      "Epoch 20/35\n",
      " - 1s - loss: 0.2731 - val_loss: 0.2718\n",
      "Epoch 21/35\n",
      " - 1s - loss: 0.2730 - val_loss: 0.2718\n",
      "Epoch 22/35\n",
      " - 1s - loss: 0.2719 - val_loss: 0.2742\n",
      "Epoch 23/35\n",
      " - 1s - loss: 0.2711 - val_loss: 0.2726\n",
      "Epoch 24/35\n",
      " - 1s - loss: 0.2700 - val_loss: 0.2728\n",
      "Epoch 25/35\n",
      " - 1s - loss: 0.2702 - val_loss: 0.2754\n",
      "Epoch 26/35\n",
      " - 1s - loss: 0.2686 - val_loss: 0.2737\n",
      "Epoch 27/35\n",
      " - 1s - loss: 0.2686 - val_loss: 0.2726\n",
      "Epoch 28/35\n",
      " - 1s - loss: 0.2680 - val_loss: 0.2736\n",
      "Epoch 29/35\n",
      " - 1s - loss: 0.2675 - val_loss: 0.2718\n",
      "Epoch 30/35\n",
      " - 1s - loss: 0.2681 - val_loss: 0.2741\n",
      "Epoch 31/35\n",
      " - 1s - loss: 0.2671 - val_loss: 0.2733\n",
      "Epoch 32/35\n",
      " - 1s - loss: 0.2671 - val_loss: 0.2722\n",
      "Epoch 33/35\n",
      " - 1s - loss: 0.2652 - val_loss: 0.2742\n",
      "Epoch 34/35\n",
      " - 1s - loss: 0.2660 - val_loss: 0.2720\n",
      "Epoch 35/35\n",
      " - 1s - loss: 0.2655 - val_loss: 0.2742\n",
      "Train on 13494 samples, validate on 1499 samples\n",
      "Epoch 1/35\n",
      " - 2s - loss: 0.3214 - val_loss: 0.2818\n",
      "Epoch 2/35\n",
      " - 1s - loss: 0.2918 - val_loss: 0.2838\n",
      "Epoch 3/35\n",
      " - 1s - loss: 0.2880 - val_loss: 0.2805\n",
      "Epoch 4/35\n",
      " - 1s - loss: 0.2870 - val_loss: 0.2808\n",
      "Epoch 5/35\n",
      " - 1s - loss: 0.2852 - val_loss: 0.2825\n",
      "Epoch 6/35\n",
      " - 1s - loss: 0.2833 - val_loss: 0.2810\n",
      "Epoch 7/35\n",
      " - 1s - loss: 0.2835 - val_loss: 0.2812\n",
      "Epoch 8/35\n",
      " - 1s - loss: 0.2825 - val_loss: 0.2797\n",
      "Epoch 9/35\n",
      " - 1s - loss: 0.2810 - val_loss: 0.2779\n",
      "Epoch 10/35\n",
      " - 1s - loss: 0.2792 - val_loss: 0.2769\n",
      "Epoch 11/35\n",
      " - 1s - loss: 0.2783 - val_loss: 0.2770\n",
      "Epoch 12/35\n",
      " - 1s - loss: 0.2772 - val_loss: 0.2777\n",
      "Epoch 13/35\n",
      " - 1s - loss: 0.2758 - val_loss: 0.2774\n",
      "Epoch 14/35\n",
      " - 1s - loss: 0.2753 - val_loss: 0.2768\n",
      "Epoch 15/35\n",
      " - 1s - loss: 0.2746 - val_loss: 0.2768\n",
      "Epoch 16/35\n",
      " - 1s - loss: 0.2734 - val_loss: 0.2756\n",
      "Epoch 17/35\n",
      " - 1s - loss: 0.2732 - val_loss: 0.2758\n",
      "Epoch 18/35\n",
      " - 1s - loss: 0.2729 - val_loss: 0.2768\n",
      "Epoch 19/35\n",
      " - 1s - loss: 0.2723 - val_loss: 0.2753\n",
      "Epoch 20/35\n",
      " - 1s - loss: 0.2708 - val_loss: 0.2756\n",
      "Epoch 21/35\n",
      " - 1s - loss: 0.2714 - val_loss: 0.2752\n",
      "Epoch 22/35\n",
      " - 1s - loss: 0.2705 - val_loss: 0.2759\n",
      "Epoch 23/35\n",
      " - 1s - loss: 0.2696 - val_loss: 0.2757\n",
      "Epoch 24/35\n",
      " - 1s - loss: 0.2696 - val_loss: 0.2765\n",
      "Epoch 25/35\n",
      " - 1s - loss: 0.2699 - val_loss: 0.2761\n",
      "Epoch 26/35\n",
      " - 1s - loss: 0.2686 - val_loss: 0.2755\n",
      "Epoch 27/35\n",
      " - 1s - loss: 0.2686 - val_loss: 0.2742\n",
      "Epoch 28/35\n",
      " - 1s - loss: 0.2675 - val_loss: 0.2744\n",
      "Epoch 29/35\n",
      " - 1s - loss: 0.2668 - val_loss: 0.2747\n",
      "Epoch 30/35\n",
      " - 1s - loss: 0.2667 - val_loss: 0.2753\n",
      "Epoch 31/35\n",
      " - 1s - loss: 0.2671 - val_loss: 0.2755\n",
      "Epoch 32/35\n",
      " - 1s - loss: 0.2649 - val_loss: 0.2757\n",
      "Epoch 33/35\n",
      " - 1s - loss: 0.2652 - val_loss: 0.2751\n",
      "Epoch 34/35\n",
      " - 1s - loss: 0.2653 - val_loss: 0.2759\n",
      "Epoch 35/35\n",
      " - 1s - loss: 0.2642 - val_loss: 0.2753\n",
      "Train on 13494 samples, validate on 1499 samples\n",
      "Epoch 1/35\n",
      " - 2s - loss: 0.3199 - val_loss: 0.2910\n",
      "Epoch 2/35\n",
      " - 1s - loss: 0.2903 - val_loss: 0.2908\n",
      "Epoch 3/35\n",
      " - 1s - loss: 0.2870 - val_loss: 0.2902\n",
      "Epoch 4/35\n",
      " - 1s - loss: 0.2850 - val_loss: 0.2892\n",
      "Epoch 5/35\n",
      " - 1s - loss: 0.2839 - val_loss: 0.2883\n",
      "Epoch 6/35\n",
      " - 1s - loss: 0.2836 - val_loss: 0.2875\n",
      "Epoch 7/35\n",
      " - 1s - loss: 0.2826 - val_loss: 0.2863\n",
      "Epoch 8/35\n",
      " - 1s - loss: 0.2813 - val_loss: 0.2857\n",
      "Epoch 9/35\n",
      " - 1s - loss: 0.2803 - val_loss: 0.2843\n",
      "Epoch 10/35\n",
      " - 1s - loss: 0.2793 - val_loss: 0.2838\n",
      "Epoch 11/35\n",
      " - 1s - loss: 0.2778 - val_loss: 0.2827\n",
      "Epoch 12/35\n",
      " - 1s - loss: 0.2765 - val_loss: 0.2820\n",
      "Epoch 13/35\n",
      " - 1s - loss: 0.2764 - val_loss: 0.2818\n",
      "Epoch 14/35\n",
      " - 1s - loss: 0.2762 - val_loss: 0.2824\n",
      "Epoch 15/35\n",
      " - 1s - loss: 0.2745 - val_loss: 0.2812\n",
      "Epoch 16/35\n",
      " - 1s - loss: 0.2738 - val_loss: 0.2803\n",
      "Epoch 17/35\n",
      " - 1s - loss: 0.2722 - val_loss: 0.2804\n",
      "Epoch 18/35\n",
      " - 1s - loss: 0.2717 - val_loss: 0.2802\n",
      "Epoch 19/35\n",
      " - 1s - loss: 0.2718 - val_loss: 0.2797\n",
      "Epoch 20/35\n",
      " - 1s - loss: 0.2710 - val_loss: 0.2800\n",
      "Epoch 21/35\n",
      " - 1s - loss: 0.2702 - val_loss: 0.2814\n",
      "Epoch 22/35\n",
      " - 1s - loss: 0.2709 - val_loss: 0.2794\n",
      "Epoch 23/35\n",
      " - 1s - loss: 0.2692 - val_loss: 0.2799\n",
      "Epoch 24/35\n",
      " - 1s - loss: 0.2683 - val_loss: 0.2794\n",
      "Epoch 25/35\n",
      " - 1s - loss: 0.2677 - val_loss: 0.2799\n",
      "Epoch 26/35\n",
      " - 1s - loss: 0.2678 - val_loss: 0.2804\n",
      "Epoch 27/35\n",
      " - 1s - loss: 0.2670 - val_loss: 0.2803\n",
      "Epoch 28/35\n",
      " - 1s - loss: 0.2675 - val_loss: 0.2799\n",
      "Epoch 29/35\n",
      " - 1s - loss: 0.2662 - val_loss: 0.2799\n",
      "Epoch 30/35\n",
      " - 1s - loss: 0.2655 - val_loss: 0.2803\n",
      "Epoch 31/35\n",
      " - 1s - loss: 0.2660 - val_loss: 0.2803\n",
      "Epoch 32/35\n",
      " - 1s - loss: 0.2656 - val_loss: 0.2811\n",
      "Epoch 33/35\n",
      " - 1s - loss: 0.2654 - val_loss: 0.2805\n",
      "Epoch 34/35\n",
      " - 1s - loss: 0.2633 - val_loss: 0.2809\n",
      "Epoch 35/35\n",
      " - 1s - loss: 0.2631 - val_loss: 0.2811\n",
      "Train on 13494 samples, validate on 1499 samples\n",
      "Epoch 1/35\n",
      " - 2s - loss: 0.3208 - val_loss: 0.2849\n",
      "Epoch 2/35\n",
      " - 1s - loss: 0.2934 - val_loss: 0.2851\n",
      "Epoch 3/35\n",
      " - 1s - loss: 0.2890 - val_loss: 0.2852\n",
      "Epoch 4/35\n",
      " - 1s - loss: 0.2856 - val_loss: 0.2861\n",
      "Epoch 5/35\n",
      " - 1s - loss: 0.2842 - val_loss: 0.2820\n",
      "Epoch 6/35\n",
      " - 1s - loss: 0.2853 - val_loss: 0.2814\n",
      "Epoch 7/35\n",
      " - 1s - loss: 0.2831 - val_loss: 0.2817\n",
      "Epoch 8/35\n",
      " - 1s - loss: 0.2814 - val_loss: 0.2817\n",
      "Epoch 9/35\n",
      " - 1s - loss: 0.2814 - val_loss: 0.2779\n",
      "Epoch 10/35\n",
      " - 1s - loss: 0.2793 - val_loss: 0.2790\n",
      "Epoch 11/35\n",
      " - 1s - loss: 0.2789 - val_loss: 0.2761\n",
      "Epoch 12/35\n",
      " - 1s - loss: 0.2766 - val_loss: 0.2757\n",
      "Epoch 13/35\n",
      " - 1s - loss: 0.2767 - val_loss: 0.2759\n",
      "Epoch 14/35\n",
      " - 1s - loss: 0.2759 - val_loss: 0.2749\n",
      "Epoch 15/35\n",
      " - 1s - loss: 0.2747 - val_loss: 0.2740\n",
      "Epoch 16/35\n",
      " - 1s - loss: 0.2750 - val_loss: 0.2757\n",
      "Epoch 17/35\n",
      " - 1s - loss: 0.2746 - val_loss: 0.2740\n",
      "Epoch 18/35\n",
      " - 1s - loss: 0.2732 - val_loss: 0.2734\n",
      "Epoch 19/35\n",
      " - 1s - loss: 0.2726 - val_loss: 0.2732\n",
      "Epoch 20/35\n",
      " - 1s - loss: 0.2718 - val_loss: 0.2734\n",
      "Epoch 21/35\n",
      " - 1s - loss: 0.2714 - val_loss: 0.2731\n",
      "Epoch 22/35\n",
      " - 1s - loss: 0.2702 - val_loss: 0.2727\n",
      "Epoch 23/35\n",
      " - 1s - loss: 0.2700 - val_loss: 0.2726\n",
      "Epoch 24/35\n",
      " - 1s - loss: 0.2705 - val_loss: 0.2731\n",
      "Epoch 25/35\n",
      " - 1s - loss: 0.2695 - val_loss: 0.2732\n",
      "Epoch 26/35\n",
      " - 1s - loss: 0.2694 - val_loss: 0.2735\n",
      "Epoch 27/35\n",
      " - 1s - loss: 0.2688 - val_loss: 0.2723\n",
      "Epoch 28/35\n",
      " - 1s - loss: 0.2681 - val_loss: 0.2742\n",
      "Epoch 29/35\n",
      " - 1s - loss: 0.2676 - val_loss: 0.2737\n",
      "Epoch 30/35\n",
      " - 1s - loss: 0.2676 - val_loss: 0.2732\n",
      "Epoch 31/35\n",
      " - 1s - loss: 0.2661 - val_loss: 0.2729\n",
      "Epoch 32/35\n",
      " - 1s - loss: 0.2676 - val_loss: 0.2727\n",
      "Epoch 33/35\n",
      " - 1s - loss: 0.2660 - val_loss: 0.2736\n",
      "Epoch 34/35\n",
      " - 1s - loss: 0.2661 - val_loss: 0.2743\n",
      "Epoch 35/35\n",
      " - 1s - loss: 0.2651 - val_loss: 0.2749\n",
      "Train on 13494 samples, validate on 1499 samples\n",
      "Epoch 1/35\n",
      " - 2s - loss: 0.3239 - val_loss: 0.2987\n",
      "Epoch 2/35\n",
      " - 1s - loss: 0.2889 - val_loss: 0.2899\n",
      "Epoch 3/35\n",
      " - 1s - loss: 0.2862 - val_loss: 0.2903\n",
      "Epoch 4/35\n",
      " - 1s - loss: 0.2855 - val_loss: 0.2888\n",
      "Epoch 5/35\n",
      " - 1s - loss: 0.2842 - val_loss: 0.2873\n",
      "Epoch 6/35\n",
      " - 1s - loss: 0.2835 - val_loss: 0.2881\n",
      "Epoch 7/35\n",
      " - 1s - loss: 0.2818 - val_loss: 0.2861\n",
      "Epoch 8/35\n",
      " - 1s - loss: 0.2801 - val_loss: 0.2859\n",
      "Epoch 9/35\n",
      " - 1s - loss: 0.2800 - val_loss: 0.2845\n",
      "Epoch 10/35\n",
      " - 1s - loss: 0.2786 - val_loss: 0.2840\n",
      "Epoch 11/35\n",
      " - 1s - loss: 0.2777 - val_loss: 0.2839\n",
      "Epoch 12/35\n",
      " - 1s - loss: 0.2759 - val_loss: 0.2831\n",
      "Epoch 13/35\n",
      " - 1s - loss: 0.2757 - val_loss: 0.2818\n",
      "Epoch 14/35\n",
      " - 1s - loss: 0.2743 - val_loss: 0.2818\n",
      "Epoch 15/35\n",
      " - 1s - loss: 0.2736 - val_loss: 0.2816\n",
      "Epoch 16/35\n",
      " - 1s - loss: 0.2746 - val_loss: 0.2813\n",
      "Epoch 17/35\n",
      " - 1s - loss: 0.2725 - val_loss: 0.2808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/35\n",
      " - 1s - loss: 0.2720 - val_loss: 0.2812\n",
      "Epoch 19/35\n",
      " - 1s - loss: 0.2712 - val_loss: 0.2808\n",
      "Epoch 20/35\n",
      " - 1s - loss: 0.2711 - val_loss: 0.2803\n",
      "Epoch 21/35\n",
      " - 1s - loss: 0.2704 - val_loss: 0.2811\n",
      "Epoch 22/35\n",
      " - 1s - loss: 0.2701 - val_loss: 0.2807\n",
      "Epoch 23/35\n",
      " - 1s - loss: 0.2699 - val_loss: 0.2811\n",
      "Epoch 24/35\n",
      " - 1s - loss: 0.2684 - val_loss: 0.2810\n",
      "Epoch 25/35\n",
      " - 1s - loss: 0.2683 - val_loss: 0.2805\n",
      "Epoch 26/35\n",
      " - 1s - loss: 0.2676 - val_loss: 0.2802\n",
      "Epoch 27/35\n",
      " - 1s - loss: 0.2668 - val_loss: 0.2805\n",
      "Epoch 28/35\n",
      " - 1s - loss: 0.2671 - val_loss: 0.2808\n",
      "Epoch 29/35\n",
      " - 1s - loss: 0.2667 - val_loss: 0.2805\n",
      "Epoch 30/35\n",
      " - 1s - loss: 0.2657 - val_loss: 0.2796\n",
      "Epoch 31/35\n",
      " - 1s - loss: 0.2657 - val_loss: 0.2795\n",
      "Epoch 32/35\n",
      " - 1s - loss: 0.2650 - val_loss: 0.2797\n",
      "Epoch 33/35\n",
      " - 1s - loss: 0.2652 - val_loss: 0.2814\n",
      "Epoch 34/35\n",
      " - 1s - loss: 0.2645 - val_loss: 0.2810\n",
      "Epoch 35/35\n",
      " - 1s - loss: 0.2633 - val_loss: 0.2803\n",
      "Train on 13494 samples, validate on 1499 samples\n",
      "Epoch 1/35\n",
      " - 2s - loss: 0.3142 - val_loss: 0.2875\n",
      "Epoch 2/35\n",
      " - 1s - loss: 0.2910 - val_loss: 0.2864\n",
      "Epoch 3/35\n",
      " - 1s - loss: 0.2868 - val_loss: 0.2853\n",
      "Epoch 4/35\n",
      " - 1s - loss: 0.2853 - val_loss: 0.2841\n",
      "Epoch 5/35\n",
      " - 1s - loss: 0.2835 - val_loss: 0.2878\n",
      "Epoch 6/35\n",
      " - 1s - loss: 0.2834 - val_loss: 0.2837\n",
      "Epoch 7/35\n",
      " - 1s - loss: 0.2822 - val_loss: 0.2846\n",
      "Epoch 8/35\n",
      " - 1s - loss: 0.2820 - val_loss: 0.2834\n",
      "Epoch 9/35\n",
      " - 1s - loss: 0.2801 - val_loss: 0.2837\n",
      "Epoch 10/35\n",
      " - 1s - loss: 0.2797 - val_loss: 0.2804\n",
      "Epoch 11/35\n",
      " - 1s - loss: 0.2784 - val_loss: 0.2802\n",
      "Epoch 12/35\n",
      " - 1s - loss: 0.2772 - val_loss: 0.2806\n",
      "Epoch 13/35\n",
      " - 1s - loss: 0.2756 - val_loss: 0.2783\n",
      "Epoch 14/35\n",
      " - 1s - loss: 0.2760 - val_loss: 0.2784\n",
      "Epoch 15/35\n",
      " - 1s - loss: 0.2757 - val_loss: 0.2791\n",
      "Epoch 16/35\n",
      " - 1s - loss: 0.2735 - val_loss: 0.2771\n",
      "Epoch 17/35\n",
      " - 1s - loss: 0.2742 - val_loss: 0.2787\n",
      "Epoch 18/35\n",
      " - 1s - loss: 0.2738 - val_loss: 0.2767\n",
      "Epoch 19/35\n",
      " - 1s - loss: 0.2719 - val_loss: 0.2769\n",
      "Epoch 20/35\n",
      " - 1s - loss: 0.2717 - val_loss: 0.2773\n",
      "Epoch 21/35\n",
      " - 1s - loss: 0.2716 - val_loss: 0.2774\n",
      "Epoch 22/35\n",
      " - 1s - loss: 0.2707 - val_loss: 0.2778\n",
      "Epoch 23/35\n",
      " - 1s - loss: 0.2699 - val_loss: 0.2768\n",
      "Epoch 24/35\n",
      " - 1s - loss: 0.2694 - val_loss: 0.2767\n",
      "Epoch 25/35\n",
      " - 1s - loss: 0.2697 - val_loss: 0.2766\n",
      "Epoch 26/35\n",
      " - 1s - loss: 0.2694 - val_loss: 0.2767\n",
      "Epoch 27/35\n",
      " - 1s - loss: 0.2684 - val_loss: 0.2777\n",
      "Epoch 28/35\n",
      " - 1s - loss: 0.2681 - val_loss: 0.2760\n",
      "Epoch 29/35\n",
      " - 1s - loss: 0.2676 - val_loss: 0.2760\n",
      "Epoch 30/35\n",
      " - 1s - loss: 0.2676 - val_loss: 0.2762\n",
      "Epoch 31/35\n",
      " - 1s - loss: 0.2664 - val_loss: 0.2776\n",
      "Epoch 32/35\n",
      " - 1s - loss: 0.2669 - val_loss: 0.2764\n",
      "Epoch 33/35\n",
      " - 1s - loss: 0.2657 - val_loss: 0.2768\n",
      "Epoch 34/35\n",
      " - 1s - loss: 0.2651 - val_loss: 0.2769\n",
      "Epoch 35/35\n",
      " - 1s - loss: 0.2646 - val_loss: 0.2775\n"
     ]
    }
   ],
   "source": [
    "num_folds = 10\n",
    "softmax = False\n",
    "kf = GroupKFold(n_splits=num_folds)\n",
    "y = train_df[\"AdoptionSpeed\"]\n",
    "fold_splits = kf.split(train_df, y, rescuerID)\n",
    "oof = np.zeros((y.shape))\n",
    "test_preds = np.zeros((test_df.shape[0]))\n",
    "if softmax == True:\n",
    "    test_preds = np.zeros((test_df.shape[0], 5))\n",
    "    oof = np.zeros(shape = (y.shape[0], 5))\n",
    "for i, (dev_index, val_index) in enumerate(fold_splits):\n",
    "    tr_df = train_df.iloc[dev_index, :]\n",
    "    val_df = train_df.iloc[val_index, :]\n",
    "    X_train = get_input_features(tr_df)\n",
    "    X_valid = get_input_features(val_df)\n",
    "    X_test = get_input_features(test_df)\n",
    "    model = make_model(softmax = softmax)\n",
    "    ckpt = ModelCheckpoint(\"model\" + str(i) + \".h5\", monitor='val_loss', save_best_only = True, verbose = False)\n",
    "    rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=5, mode='auto', verbose = False)\n",
    "    if softmax == True:\n",
    "        y_train = np.zeros(shape = (tr_df.shape[0], 5))\n",
    "        y_valid = np.zeros(shape = (val_df.shape[0], 5))\n",
    "        for j, l in enumerate(tr_df['AdoptionSpeed'].values):\n",
    "            j = int(j)\n",
    "            l = int(l)\n",
    "            y_train[j,l] = 1\n",
    "        for j, l in enumerate(val_df['AdoptionSpeed'].values):\n",
    "            j = int(j)\n",
    "            l = int(l)\n",
    "            y_valid[j,l] = 1\n",
    "    else:\n",
    "        y_train = tr_df['AdoptionSpeed'].values / 4\n",
    "        y_valid = val_df['AdoptionSpeed'].values / 4\n",
    "\n",
    "    \n",
    "\n",
    "    hist = model.fit(X_train, y_train, validation_data = (X_valid,y_valid), batch_size = 500, epochs = 35, verbose = 2, callbacks = [ckpt, rlr])\n",
    "    model.load_weights(\"model\" + str(i) + \".h5\")\n",
    "    if softmax == True:\n",
    "        val_preds = model.predict(X_valid)\n",
    "        oof[val_index] = val_preds\n",
    "        test_pred = model.predict(X_test)\n",
    "        test_preds += (test_pred/num_folds)\n",
    "    else:\n",
    "        val_preds = model.predict(X_valid)[:, 0] * 4\n",
    "        y_valid = y_valid * 4\n",
    "        optR = OptimizedRounder()\n",
    "        optR.fit(val_preds, y_valid)\n",
    "        coefficients = optR.coefficients()\n",
    "        val_pred_rounded = optR.predict(val_preds, coefficients)\n",
    "        oof[val_index] = val_preds\n",
    "        test_pred = model.predict(X_test)[:, 0] * 4\n",
    "        test_preds += (test_pred/num_folds)\n",
    "if softmax == True:\n",
    "    oof_rounded = np.argmax(oof, axis = 1)\n",
    "    test_rounded = np.argmax(test_preds, axis = 1)\n",
    "else:\n",
    "    optR = OptimizedRounder()\n",
    "    optR.fit(oof, y)\n",
    "    coefficients = optR.coefficients()\n",
    "    oof_rounded = optR.predict(oof, coefficients)\n",
    "    test_rounded = optR.predict(test_preds, coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3517253416755485\n"
     ]
    }
   ],
   "source": [
    "print(quadratic_weighted_kappa(y, oof_rounded))\n",
    "oof_nn = oof\n",
    "test_preds_nn = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.6137766975278947, 2.0834985176409457, 2.5196431100130403, 2.8818759074876565]\n",
      "0.3517253416755485\n"
     ]
    }
   ],
   "source": [
    "#nn only\n",
    "if softmax == False:\n",
    "    optR = OptimizedRounder()\n",
    "    optR.fit(oof_nn, y)\n",
    "    coefficients = optR.coefficients()\n",
    "    print(coefficients)\n",
    "    oof_rounded = optR.predict(oof_nn, coefficients)\n",
    "    print(quadratic_weighted_kappa(y, oof_rounded))\n",
    "    test_rounded_nn = optR.predict(test_preds_nn, coefficients)\n",
    "if softmax == True:\n",
    "    oof_rounded = np.argmax(oof_nn, axis = 1)\n",
    "    test_rounded_nn = np.argmax(test_preds_nn, axis = 1)\n",
    "    print(quadratic_weighted_kappa(y, oof_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop('Name', axis = 1, inplace = True)\n",
    "train_df.drop('RescuerID', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = deepcopy(train_df)\n",
    "test = deepcopy(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14993, 290)\n",
      "(3972, 291)\n"
     ]
    }
   ],
   "source": [
    "train.loc[:, cat_cols] = train[cat_cols].astype('category')\n",
    "test.loc[:, cat_cols] = test[cat_cols].astype('category')\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(set(['Description', 'Description1', 'PetID', 'AdoptionSpeed']), axis=1, inplace=True)\n",
    "test.drop(set([ 'Description', 'Description1', 'PetID']), axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(set(['Name', 'RescuerID']), axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv(\"../input/petfinder-adoption-prediction/train/train.csv\")['AdoptionSpeed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "ITERATIONS = 10 # 1000\n",
    "TRAINING_SIZE = 100000 # 20000000\n",
    "TEST_SIZE = 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "bayes_cv_tuner = BayesSearchCV(\n",
    "    estimator = xgb.XGBClassifier(\n",
    "        n_jobs = 1,\n",
    "        eval_metric='rmse',\n",
    "        silent=1,\n",
    "        tree_method='approx',\n",
    "        device = 'gpu'\n",
    "    ),\n",
    "    search_spaces = {\n",
    "        'learning_rate': (0.01, 1.0, 'log-uniform'),\n",
    "        'min_child_weight': (0, 10),\n",
    "        'max_depth': (0, 50),\n",
    "        'max_delta_step': (0, 20),\n",
    "        'subsample': (0.01, 1.0, 'uniform'),\n",
    "        'colsample_bytree': (0.01, 1.0, 'uniform'),\n",
    "        'colsample_bylevel': (0.01, 1.0, 'uniform'),\n",
    "        'reg_lambda': (1e-9, 1000, 'log-uniform'),\n",
    "        'reg_alpha': (1e-9, 1.0, 'log-uniform'),\n",
    "        'gamma': (1e-9, 0.5, 'log-uniform'),\n",
    "        'min_child_weight': (0, 5),\n",
    "        'n_estimators': (50, 100),\n",
    "        'scale_pos_weight': (1e-6, 500, 'log-uniform')\n",
    "    },  \n",
    "    scoring=None,\n",
    "    cv = StratifiedKFold(\n",
    "        n_splits=5,\n",
    "        shuffle=True,\n",
    "        random_state=42\n",
    "    ),\n",
    "    n_jobs = 3,\n",
    "    n_iter = ITERATIONS,   \n",
    "    verbose = 0,\n",
    "    refit = True,\n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "def status_print(optim_result):\n",
    "    \"\"\"Status callback durring bayesian hyperparameter search\"\"\"\n",
    "    \n",
    "    # Get all the models tested so far in DataFrame format\n",
    "    all_models = pd.DataFrame(bayes_cv_tuner.cv_results_)    \n",
    "    \n",
    "    # Get current parameters and the best parameters    \n",
    "    best_params = pd.Series(bayes_cv_tuner.best_params_)\n",
    "    print('Model #{}\\nBest ROC-AUC: {}\\nBest params: {}\\n'.format(\n",
    "        len(all_models),\n",
    "        np.round(bayes_cv_tuner.best_score_, 4),\n",
    "        bayes_cv_tuner.best_params_\n",
    "    ))\n",
    "    \n",
    "    # Save all model results\n",
    "    clf_name = bayes_cv_tuner.estimator.__class__.__name__\n",
    "    all_models.to_csv(clf_name+\"_cv_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = bayes_cv_tuner.fit(train.values, y, callback=status_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "xgb_params = {\n",
    "    'eval_metric': 'rmse',\n",
    "    'seed': 1337,\n",
    "    'eta': 0.0123,\n",
    "    'subsample': 1.0,\n",
    "    'colsample_bytree': 0.6,\n",
    "    'min_child_weight': 1.0,\n",
    "    'gamma' : .5,\n",
    "    'max_depth' : 5,\n",
    "    'tree_method': 'gpu_hist',\n",
    "    'device': 'gpu',\n",
    "    'silent': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_xgb(params, X_train, X_test):\n",
    "    n_splits = 20\n",
    "    verbose_eval = 1000\n",
    "    num_rounds = 30000\n",
    "    early_stop = 500\n",
    "\n",
    "    kf = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "    oof_train = np.zeros((X_train.shape[0]))\n",
    "    oof_test = np.zeros((X_test.shape[0], n_splits))\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    for train_idx, valid_idx in kf.split(X_train, y,  rescuerID):\n",
    "\n",
    "        X_tr = X_train.iloc[train_idx, :]\n",
    "        X_val = X_train.iloc[valid_idx, :]\n",
    "\n",
    "        y_tr = y.iloc[train_idx]\n",
    "        y_val = y.iloc[valid_idx]\n",
    "        d_train = xgb.DMatrix(data=X_tr, label=y_tr, feature_names=X_tr.columns)\n",
    "        d_valid = xgb.DMatrix(data=X_val, label=y_val, feature_names=X_val.columns)\n",
    "\n",
    "        watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "        model = xgb.train(dtrain=d_train, num_boost_round=num_rounds, evals=watchlist,\n",
    "                         early_stopping_rounds=early_stop, verbose_eval=verbose_eval, params=params)\n",
    "\n",
    "        valid_pred = model.predict(xgb.DMatrix(X_val, feature_names=X_val.columns), ntree_limit=model.best_ntree_limit)\n",
    "        test_pred = model.predict(xgb.DMatrix(X_test, feature_names=X_test.columns), ntree_limit=model.best_ntree_limit)\n",
    "\n",
    "        oof_train[valid_idx] = valid_pred\n",
    "        oof_test[:, i] = test_pred\n",
    "\n",
    "        i += 1\n",
    "    return model, oof_train, oof_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[cat_cols] = train[cat_cols].astype(int)\n",
    "test[cat_cols] = test[cat_cols].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:2.31723\tvalid-rmse:2.22334\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 500 rounds.\n",
      "[1000]\ttrain-rmse:0.809012\tvalid-rmse:0.927741\n",
      "Stopping. Best iteration:\n",
      "[906]\ttrain-rmse:0.825034\tvalid-rmse:0.926785\n",
      "\n",
      "[0]\ttrain-rmse:2.31224\tvalid-rmse:2.31866\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 500 rounds.\n",
      "[1000]\ttrain-rmse:0.796428\tvalid-rmse:1.03631\n",
      "[2000]\ttrain-rmse:0.6539\tvalid-rmse:1.03358\n",
      "Stopping. Best iteration:\n",
      "[1747]\ttrain-rmse:0.685864\tvalid-rmse:1.03242\n",
      "\n",
      "[0]\ttrain-rmse:2.31114\tvalid-rmse:2.34092\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 500 rounds.\n",
      "[1000]\ttrain-rmse:0.798578\tvalid-rmse:1.02495\n",
      "[2000]\ttrain-rmse:0.658882\tvalid-rmse:1.0247\n",
      "Stopping. Best iteration:\n",
      "[1556]\ttrain-rmse:0.715554\tvalid-rmse:1.0228\n",
      "\n",
      "[0]\ttrain-rmse:2.32003\tvalid-rmse:2.16491\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 500 rounds.\n",
      "[1000]\ttrain-rmse:0.798808\tvalid-rmse:1.02056\n",
      "[2000]\ttrain-rmse:0.652037\tvalid-rmse:1.01767\n",
      "Stopping. Best iteration:\n",
      "[1947]\ttrain-rmse:0.659228\tvalid-rmse:1.01723\n",
      "\n",
      "[0]\ttrain-rmse:2.30442\tvalid-rmse:2.46461\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 500 rounds.\n",
      "[1000]\ttrain-rmse:0.797729\tvalid-rmse:1.09057\n",
      "Stopping. Best iteration:\n",
      "[957]\ttrain-rmse:0.805367\tvalid-rmse:1.09005\n",
      "\n",
      "[0]\ttrain-rmse:2.31943\tvalid-rmse:2.17783\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 500 rounds.\n",
      "[1000]\ttrain-rmse:0.802385\tvalid-rmse:1.05149\n",
      "Stopping. Best iteration:\n",
      "[1411]\ttrain-rmse:0.736658\tvalid-rmse:1.04939\n",
      "\n",
      "[0]\ttrain-rmse:2.31537\tvalid-rmse:2.25879\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 500 rounds.\n",
      "[1000]\ttrain-rmse:0.802567\tvalid-rmse:1.09729\n",
      "[2000]\ttrain-rmse:0.656399\tvalid-rmse:1.09598\n",
      "Stopping. Best iteration:\n",
      "[1946]\ttrain-rmse:0.663037\tvalid-rmse:1.09571\n",
      "\n",
      "[0]\ttrain-rmse:2.30679\tvalid-rmse:2.42193\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 500 rounds.\n",
      "[1000]\ttrain-rmse:0.800685\tvalid-rmse:1.06692\n",
      "Stopping. Best iteration:\n",
      "[1017]\ttrain-rmse:0.797809\tvalid-rmse:1.06636\n",
      "\n",
      "[0]\ttrain-rmse:2.30787\tvalid-rmse:2.4025\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 500 rounds.\n",
      "[1000]\ttrain-rmse:0.795852\tvalid-rmse:1.10363\n",
      "[2000]\ttrain-rmse:0.657033\tvalid-rmse:1.10274\n",
      "Stopping. Best iteration:\n",
      "[1681]\ttrain-rmse:0.696476\tvalid-rmse:1.10107\n",
      "\n",
      "[0]\ttrain-rmse:2.3114\tvalid-rmse:2.33576\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 500 rounds.\n",
      "[1000]\ttrain-rmse:0.801696\tvalid-rmse:1.05717\n",
      "Stopping. Best iteration:\n",
      "[667]\ttrain-rmse:0.863323\tvalid-rmse:1.0562\n",
      "\n",
      "[0]\ttrain-rmse:2.31645\tvalid-rmse:2.23839\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 500 rounds.\n",
      "[1000]\ttrain-rmse:0.797768\tvalid-rmse:0.985676\n",
      "[2000]\ttrain-rmse:0.652276\tvalid-rmse:0.980142\n",
      "[3000]\ttrain-rmse:0.544003\tvalid-rmse:0.97923\n",
      "Stopping. Best iteration:\n",
      "[2569]\ttrain-rmse:0.587153\tvalid-rmse:0.97821\n",
      "\n",
      "[0]\ttrain-rmse:2.31898\tvalid-rmse:2.18775\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 500 rounds.\n",
      "[1000]\ttrain-rmse:0.800358\tvalid-rmse:1.0256\n",
      "Stopping. Best iteration:\n",
      "[1007]\ttrain-rmse:0.799353\tvalid-rmse:1.02544\n",
      "\n",
      "[0]\ttrain-rmse:2.30971\tvalid-rmse:2.36737\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 500 rounds.\n",
      "[1000]\ttrain-rmse:0.805137\tvalid-rmse:1.00191\n",
      "[2000]\ttrain-rmse:0.662903\tvalid-rmse:0.997392\n",
      "Stopping. Best iteration:\n",
      "[1784]\ttrain-rmse:0.689794\tvalid-rmse:0.996903\n",
      "\n",
      "[0]\ttrain-rmse:2.30777\tvalid-rmse:2.40434\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 500 rounds.\n",
      "[1000]\ttrain-rmse:0.798773\tvalid-rmse:1.13408\n",
      "Stopping. Best iteration:\n",
      "[885]\ttrain-rmse:0.818985\tvalid-rmse:1.13295\n",
      "\n",
      "[0]\ttrain-rmse:2.31323\tvalid-rmse:2.30085\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 500 rounds.\n",
      "[1000]\ttrain-rmse:0.799058\tvalid-rmse:1.05598\n",
      "[2000]\ttrain-rmse:0.659984\tvalid-rmse:1.05567\n",
      "Stopping. Best iteration:\n",
      "[1674]\ttrain-rmse:0.700494\tvalid-rmse:1.05377\n",
      "\n",
      "[0]\ttrain-rmse:2.31217\tvalid-rmse:2.32176\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 500 rounds.\n",
      "[1000]\ttrain-rmse:0.797224\tvalid-rmse:1.08891\n",
      "Stopping. Best iteration:\n",
      "[774]\ttrain-rmse:0.837321\tvalid-rmse:1.08763\n",
      "\n",
      "[0]\ttrain-rmse:2.31031\tvalid-rmse:2.35576\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 500 rounds.\n",
      "[1000]\ttrain-rmse:0.800538\tvalid-rmse:1.04232\n",
      "Stopping. Best iteration:\n",
      "[593]\ttrain-rmse:0.879439\tvalid-rmse:1.04046\n",
      "\n",
      "[0]\ttrain-rmse:2.3185\tvalid-rmse:2.19601\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 500 rounds.\n",
      "[1000]\ttrain-rmse:0.798889\tvalid-rmse:1.0821\n",
      "Stopping. Best iteration:\n",
      "[1149]\ttrain-rmse:0.774181\tvalid-rmse:1.08149\n",
      "\n",
      "[0]\ttrain-rmse:2.30977\tvalid-rmse:2.36712\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 500 rounds.\n",
      "[1000]\ttrain-rmse:0.801924\tvalid-rmse:1.03992\n",
      "Stopping. Best iteration:\n",
      "[1236]\ttrain-rmse:0.763898\tvalid-rmse:1.0383\n",
      "\n",
      "[0]\ttrain-rmse:2.30924\tvalid-rmse:2.37697\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 500 rounds.\n",
      "[1000]\ttrain-rmse:0.797676\tvalid-rmse:1.05136\n",
      "Stopping. Best iteration:\n",
      "[930]\ttrain-rmse:0.809248\tvalid-rmse:1.05051\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model, oof_train, oof_test = run_xgb(xgb_params, train[train.columns.unique()], test[test.columns.unique()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QWK =  0.4398871359006301\n"
     ]
    }
   ],
   "source": [
    "optR = OptimizedRounder()\n",
    "optR.fit(oof_train, y)\n",
    "coefficients = optR.coefficients()\n",
    "oof_xgb = optR.predict(oof_train, coefficients)\n",
    "qwk = quadratic_weighted_kappa(y, oof_xgb)\n",
    "print(\"QWK = \", qwk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_xgb = optR.predict(oof_test.mean(axis=1), coefficients).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lightgb(params, X_train, X_test):\n",
    "    n_splits = 20\n",
    "    verbose_eval = 1000\n",
    "    num_rounds = 30000\n",
    "    early_stop = 500\n",
    "\n",
    "    kf = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "    oof_train = np.zeros((X_train.shape[0]))\n",
    "    oof_test = np.zeros((X_test.shape[0], n_splits))\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    for train_idx, valid_idx in kf.split(X_train, y,  rescuerID):\n",
    "\n",
    "        X_tr = X_train.iloc[train_idx, :]\n",
    "        X_val = X_train.iloc[valid_idx, :]\n",
    "\n",
    "        y_tr = y.iloc[train_idx]\n",
    "        y_val = y.iloc[valid_idx]\n",
    "        d_train = lgb.Dataset(X_tr, label=y_tr)\n",
    "        d_valid = lgb.Dataset(X_val, label=y_val)\n",
    "\n",
    "        watchlist = [d_train, d_valid]\n",
    "        model = lgb.train(params,\n",
    "                          train_set=d_train,\n",
    "                          num_boost_round=num_rounds,\n",
    "                          valid_sets=watchlist,\n",
    "                          verbose_eval=verbose_eval,\n",
    "                          early_stopping_rounds=early_stop)\n",
    "        \n",
    "        valid_pred = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "        test_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "\n",
    "        oof_train[valid_idx] = valid_pred\n",
    "        oof_test[:, i] = test_pred\n",
    "\n",
    "        i += 1\n",
    "    return model, oof_train, oof_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'application': 'regression',\n",
    "          'boosting': 'gbdt',\n",
    "          'metric': 'rmse',\n",
    "          'num_leaves': 70,\n",
    "          'max_depth': 9,\n",
    "          'learning_rate': 0.01,\n",
    "          'bagging_fraction': 0.85,\n",
    "          'feature_fraction': 0.8,\n",
    "          'min_split_gain': 0.02,\n",
    "          'min_child_samples': 150,\n",
    "          'min_child_weight': 0.02,\n",
    "          'lambda_l2': 0.0475,\n",
    "          'verbosity': -1,\n",
    "          'data_random_seed': 17}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[1000]\ttraining's rmse: 0.737427\tvalid_1's rmse: 0.924772\n",
      "[2000]\ttraining's rmse: 0.588358\tvalid_1's rmse: 0.919144\n",
      "Early stopping, best iteration is:\n",
      "[2373]\ttraining's rmse: 0.541834\tvalid_1's rmse: 0.918478\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[1000]\ttraining's rmse: 0.735683\tvalid_1's rmse: 1.02779\n",
      "Early stopping, best iteration is:\n",
      "[1052]\ttraining's rmse: 0.726502\tvalid_1's rmse: 1.02717\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[1000]\ttraining's rmse: 0.735442\tvalid_1's rmse: 1.02112\n",
      "Early stopping, best iteration is:\n",
      "[1113]\ttraining's rmse: 0.716416\tvalid_1's rmse: 1.02057\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[1000]\ttraining's rmse: 0.733215\tvalid_1's rmse: 1.0071\n",
      "Early stopping, best iteration is:\n",
      "[1408]\ttraining's rmse: 0.662414\tvalid_1's rmse: 1.0064\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[1000]\ttraining's rmse: 0.734933\tvalid_1's rmse: 1.0926\n",
      "Early stopping, best iteration is:\n",
      "[1301]\ttraining's rmse: 0.683921\tvalid_1's rmse: 1.09235\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[1000]\ttraining's rmse: 0.733045\tvalid_1's rmse: 1.05899\n",
      "Early stopping, best iteration is:\n",
      "[644]\ttraining's rmse: 0.808113\tvalid_1's rmse: 1.05832\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[1000]\ttraining's rmse: 0.732465\tvalid_1's rmse: 1.09105\n",
      "[2000]\ttraining's rmse: 0.584072\tvalid_1's rmse: 1.0879\n",
      "Early stopping, best iteration is:\n",
      "[1539]\ttraining's rmse: 0.644094\tvalid_1's rmse: 1.0863\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[1000]\ttraining's rmse: 0.737624\tvalid_1's rmse: 1.07197\n",
      "Early stopping, best iteration is:\n",
      "[1299]\ttraining's rmse: 0.689594\tvalid_1's rmse: 1.07079\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[1000]\ttraining's rmse: 0.738743\tvalid_1's rmse: 1.10099\n",
      "Early stopping, best iteration is:\n",
      "[1303]\ttraining's rmse: 0.689284\tvalid_1's rmse: 1.10025\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[1000]\ttraining's rmse: 0.738085\tvalid_1's rmse: 1.0565\n",
      "Early stopping, best iteration is:\n",
      "[741]\ttraining's rmse: 0.785836\tvalid_1's rmse: 1.05333\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[1000]\ttraining's rmse: 0.733986\tvalid_1's rmse: 0.990298\n",
      "Early stopping, best iteration is:\n",
      "[948]\ttraining's rmse: 0.743619\tvalid_1's rmse: 0.990085\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[487]\ttraining's rmse: 0.846974\tvalid_1's rmse: 1.03015\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[1000]\ttraining's rmse: 0.738458\tvalid_1's rmse: 0.996477\n",
      "Early stopping, best iteration is:\n",
      "[1371]\ttraining's rmse: 0.677838\tvalid_1's rmse: 0.995208\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[1000]\ttraining's rmse: 0.730456\tvalid_1's rmse: 1.13542\n",
      "Early stopping, best iteration is:\n",
      "[1345]\ttraining's rmse: 0.67319\tvalid_1's rmse: 1.13367\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[1000]\ttraining's rmse: 0.736725\tvalid_1's rmse: 1.05475\n",
      "Early stopping, best iteration is:\n",
      "[1055]\ttraining's rmse: 0.727333\tvalid_1's rmse: 1.05412\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[1000]\ttraining's rmse: 0.725756\tvalid_1's rmse: 1.08978\n",
      "Early stopping, best iteration is:\n",
      "[1125]\ttraining's rmse: 0.704438\tvalid_1's rmse: 1.08862\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[1000]\ttraining's rmse: 0.732137\tvalid_1's rmse: 1.03494\n",
      "Early stopping, best iteration is:\n",
      "[521]\ttraining's rmse: 0.838009\tvalid_1's rmse: 1.03324\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[1000]\ttraining's rmse: 0.734622\tvalid_1's rmse: 1.07465\n",
      "Early stopping, best iteration is:\n",
      "[1152]\ttraining's rmse: 0.708254\tvalid_1's rmse: 1.07369\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[1000]\ttraining's rmse: 0.733763\tvalid_1's rmse: 1.02654\n",
      "Early stopping, best iteration is:\n",
      "[1450]\ttraining's rmse: 0.657818\tvalid_1's rmse: 1.02334\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[1000]\ttraining's rmse: 0.732618\tvalid_1's rmse: 1.04318\n",
      "Early stopping, best iteration is:\n",
      "[800]\ttraining's rmse: 0.769879\tvalid_1's rmse: 1.04183\n"
     ]
    }
   ],
   "source": [
    "model_lgb, oof_train_lgb, oof_test_lgb = run_lightgb(params, train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QWK =  0.44155758472022133\n"
     ]
    }
   ],
   "source": [
    "optR = OptimizedRounder()\n",
    "optR.fit(oof_train_lgb, y)\n",
    "coefficients_lgb = optR.coefficients()\n",
    "oof_lgb = optR.predict(oof_train_lgb, coefficients_lgb)\n",
    "qwk = quadratic_weighted_kappa(y, oof_lgb)\n",
    "print(\"QWK = \", qwk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_models = [oof_nn, oof_train_lgb, oof_train]\n",
    "test_models = [test_preds_nn, oof_test_lgb.mean(axis = 1), oof_test.mean(axis = 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16130901 0.57910042 0.26836402]\n",
      "[0.15990608 0.5740639  0.26603002]\n",
      "[1.6142293127014717, 2.117959182689082, 2.57035041019707, 2.8267579199206834]\n",
      "0.446773537312916\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "lr = Ridge(fit_intercept=False)\n",
    "lr.fit(np.array(oof_models).T, y)\n",
    "print(lr.coef_)\n",
    "lr.coef_ = lr.coef_ * 1/(sum(lr.coef_))\n",
    "print(lr.coef_)\n",
    "oof_lr = lr.predict(np.array(oof_models).T)\n",
    "test_preds_lr = lr.predict(np.array(test_models).T)\n",
    "#lr of nn and lgb and xgb\n",
    "optR = OptimizedRounder()\n",
    "optR.fit(oof_lr, y)\n",
    "coefficients = optR.coefficients()\n",
    "print(coefficients)\n",
    "oof_rounded = optR.predict(oof_lr, coefficients)\n",
    "print(quadratic_weighted_kappa(y, oof_rounded))\n",
    "test_rounded_lr = optR.predict(test_preds_lr, coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame()\n",
    "fold_importance = pd.DataFrame()\n",
    "fold_importance[\"feature\"] = train.columns              \n",
    "fold_importance[\"importance\"] = model_lgb.feature_importance()\n",
    "feature_importance = pd.concat([feature_importance, fold_importance], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x864 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
    "                by=\"importance\", ascending=False)[:50].index\n",
    "\n",
    "best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n",
    "\n",
    "plt.figure(figsize=(16, 12));\n",
    "sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\n",
    "plt.title('LGB Features (avg over folds)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'PetID': pd.read_csv(\"../input/petfinder-adoption-prediction/test/test.csv\")['PetID'].values, 'AdoptionSpeed': test_rounded_lr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-83c839f2ecee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'submission.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   1743\u001b[0m                                  \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1744\u001b[0m                                  escapechar=escapechar, decimal=decimal)\n\u001b[0;32m-> 1745\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1747\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnicodeWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mwriter_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         libwriters.write_csv_rows(self.data, ix, self.nlevels,\n\u001b[0;32m--> 313\u001b[0;31m                                   self.cols, self.writer)\n\u001b[0m",
      "\u001b[0;32mpandas/_libs/writers.pyx\u001b[0m in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
